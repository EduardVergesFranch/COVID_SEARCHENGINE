{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Engine\n",
    "\n",
    "This script implements the search engine for tweets related to COVID-19. Usage:\n",
    "* Download required files from Google Drive or execute `Indexing.ipynb`.\n",
    "* Execute cells until declaring `TwitterSearch` class.\n",
    "* Initialize an instance of this class (called SE in this code).\n",
    "* Call the method `interface` to launch the interface to interact with the search engine.\n",
    "* Introduce -1 in the number of tweets to be retrieved to stop the execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important note\n",
    "\n",
    "#### Download required files stored in Google Drive\n",
    "This script requires the file `inverted_index.json` and `tweets_with_authority.csv` that can be downloaded from the Google Drive Folder (`https://drive.google.com/drive/u/1/folders/16I4_ZCre59ufD9lDZbFK9cn1mALRmPjB`). The file must be stored in the `~/data` folder as specified in the README."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We specify the path for importing modules\n",
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 862,
     "status": "ok",
     "timestamp": 1607422891332,
     "user": {
      "displayName": "JAVIER RANDO",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiNPaYf78UhV7NkeRoHbkKX8Kt0UJY7GUBA6fN9TQ=s64",
      "userId": "02059478865524595396"
     },
     "user_tz": -60
    },
    "id": "GMv7w01T1bk9",
    "outputId": "968837f6-663c-44ea-9290-bdcac6ee78a8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from utils import clean_text, personalized_tokenizer\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/javi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTHORITY_DATASET = \"tweets_with_authority.csv\"\n",
    "INVERTED_INDEX = \"inverted_index.json\"\n",
    "VECTORIZER = \"vectorizer.pickle\"\n",
    "INPUT_PATH = \"../data/\"\n",
    "MODES = ['1', '2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwitterSearch:\n",
    "    def __init__(self):\n",
    "        self.data, self.corpus, self.vectorizer, self.inverted_index = self._load_information()\n",
    "\n",
    "    def _load_information(self):\n",
    "        # Load pretrained vectorizer\n",
    "        vectorizer = pickle.load(open(INPUT_PATH + VECTORIZER, \"rb\"))\n",
    "\n",
    "        # Load corpus\n",
    "        df = pd.read_csv(INPUT_PATH + AUTHORITY_DATASET)\n",
    "        corpus = df['clean_text']\n",
    "        corpus = corpus.fillna('')\n",
    "        corpus = vectorizer.transform(corpus)\n",
    "        \n",
    "        with open(INPUT_PATH + INVERTED_INDEX, 'r') as f:\n",
    "            inverted_index = json.load(f)\n",
    "\n",
    "        return df, corpus, vectorizer, inverted_index\n",
    "\n",
    "    def _get_tweet_fields(self, i):\n",
    "        \"\"\"\n",
    "        Returns the relevant fields for each tweet\n",
    "        i: id of the tweet we want to extract the information\n",
    "        returns various fields needed for showing the result to the user\n",
    "        \"\"\"\n",
    "        df = self.data\n",
    "        user_name = eval(df.iloc[i]['user'])['name']\n",
    "        text = df.iloc[i]['full_text']\n",
    "        entities = eval(df.iloc[i]['entities'])\n",
    "        urls = entities['urls']\n",
    "        if urls:\n",
    "            url = urls[0]['url']\n",
    "            text = text.replace(url, '')\n",
    "        else:\n",
    "            url = 'No url'\n",
    "\n",
    "        hashtags = entities['hashtags']\n",
    "\n",
    "        if not hashtags:\n",
    "            hashtags = 'No hashtags'\n",
    "\n",
    "        favorite_count = df.iloc[i]['favorite_count']\n",
    "        retweet_count = df.iloc[i]['retweet_count']\n",
    "        followers_count = df.iloc[i]['followers_count']\n",
    "\n",
    "        return user_name, text, url, hashtags, favorite_count, retweet_count, followers_count\n",
    "\n",
    "    def find_full_match_docs(self, query):\n",
    "        \"\"\"\n",
    "        Return the indexes of the documents containing all terms in the query\n",
    "        \"\"\"\n",
    "        docs = None\n",
    "\n",
    "        for word in query.split():\n",
    "            if docs is None:\n",
    "                docs = set([i[0] for i in self.inverted_index[word]])\n",
    "            else:\n",
    "                try:\n",
    "                    docs = docs.intersection(set([i[0] for i in self.inverted_index[word]]))\n",
    "                except:\n",
    "                    docs = docs\n",
    "                    \n",
    "        return list(self.data[self.data['id_str'].isin(docs)].index)\n",
    "    \n",
    "    def _get_hashtags(self, hashtags):\n",
    "        hashtags = hashtags[:]\n",
    "        clean_hashtags = []\n",
    "        if hashtags != 'No hashtags':\n",
    "            for h in hashtags:\n",
    "                clean_hashtags.append('#'+h['text'])\n",
    "            return ', '.join(clean_hashtags)\n",
    "        else:\n",
    "            return 'No hashtags'\n",
    "    \n",
    "    def return_top_n_doc(self,query,n,show = True,authority = None):\n",
    "        \"\"\"\n",
    "        query: Query that the user writes.\n",
    "        tf_idf: dataframe containing tfidf weights for each word in each doc\n",
    "        n: number of doc to return to the user\n",
    "        show: if you want to visualize the results\n",
    "\n",
    "        returns a list with the most top n relevant tweets\n",
    "        \"\"\"\n",
    "        assert n>0, \"n should be a positive integer\"\n",
    "        query = clean_text(query) #noramalize the query\n",
    "        query_vec = self.vectorizer.transform([query]) #calculate tdidf\n",
    "        results = cosine_similarity(self.corpus, query_vec)\n",
    "        results = results.flatten()\n",
    "\n",
    "        documents_retrieved = []\n",
    "\n",
    "        #######Return the results#########\n",
    "        rank=0\n",
    "\n",
    "        if authority is not None:\n",
    "            results = 3*results*0.5*authority\n",
    "\n",
    "        # Reverse the results\n",
    "        results = results.argsort()[::-1]\n",
    "\n",
    "        ## Generate print mask for results\n",
    "\n",
    "        # The mask will contain the indexes from the results array in printing order\n",
    "        # By default this mask will be the first n results of our cosine similarity output\n",
    "        mask = [i for i in range(n)]\n",
    "\n",
    "        # We find those documents that contain all the terms in the query\n",
    "        full_matches = np.array(self.find_full_match_docs(query))\n",
    "\n",
    "        # If we have more full matches than desired results, we just use them in order to print\n",
    "        if len(full_matches)>=n:\n",
    "            mask = list(np.where(np.isin(results, full_matches))[0])\n",
    "\n",
    "        elif len(full_matches)==0:\n",
    "            pass    \n",
    "        # If not, we will include first those with full match and the remaining ones will be ordered\n",
    "        # simply by cosine similarity\n",
    "        else:\n",
    "            full_rank = 0\n",
    "            mask = [i for i in mask if results[i] not in full_matches] # Remove values in full matches to avoid duplicates\n",
    "            for i in range(len(results)):\n",
    "                if results[i] in full_matches:\n",
    "                    # Insert the full matches at the beggining to preserve the order of the remaining results\n",
    "                    mask.insert(full_rank, i) \n",
    "                    full_rank+=1\n",
    "\n",
    "        # Ensure we will only print n results\n",
    "        mask = mask[:n]\n",
    "\n",
    "        # Print following the order determined by the mask\n",
    "        for i in mask:\n",
    "            i = int(i)\n",
    "            user_name, text, url, hashtags, favorites, retweets, followers = self._get_tweet_fields(results[i])\n",
    "            if show == True:\n",
    "                print(\"-->\",rank + 1)\n",
    "                print(text,\" | \",user_name,\" | \",self.data.iloc[results[i]]['created_at'],\" | \", self._get_hashtags(hashtags) ,\" | Favorites: \",favorites,\" | Retweets: \", retweets,\" | \",url, \" | Followers: \", followers)\n",
    "                print('\\n')\n",
    "            documents_retrieved.append(results[i])\n",
    "            rank +=1\n",
    "\n",
    "        return documents_retrieved\n",
    "\n",
    "    def query(self, query, n=20, show=True, authority=None):\n",
    "        self.return_top_n_doc(query, n, show, authority)\n",
    "\n",
    "    def interface(self):\n",
    "        while True:\n",
    "            n = int(input(\"Enter the desired number of results: \"))\n",
    "            if n<=0:\n",
    "                print('Stopping Search Engine... Good Bye and See You Soon :)')\n",
    "                break\n",
    "            \n",
    "            while True:\n",
    "                mode = str(input(\"\"\"Which mode would you like to use (insert number for the desired option)\\n1: TF-IDF\\n2: TF-IDF and authority\\n\"\"\"))\n",
    "                \n",
    "                if mode in MODES:\n",
    "                    break\n",
    "                else:\n",
    "                    print(\"Please insert some of these options: {}\".format(', '.join(MODES)))\n",
    "\n",
    "            query = input(\"Enter your query: \")\n",
    "            if mode == \"1\":\n",
    "                self.query(query, n, show=True, authority=None)\n",
    "            elif mode == \"2\":\n",
    "                self.query(query, n, show=True, authority=self.data.authority_interp.values)\n",
    "            \n",
    "            while True:\n",
    "                br = input(\"Do you want to input another query [y/n]: \")\n",
    "                if br in ['y', 'n']:\n",
    "                    break\n",
    "                else:\n",
    "                    print('Please enter a valid value (y: yes, n: no)')\n",
    "            \n",
    "            if br == 'n':\n",
    "                print('Stopping Search Engine... Good Bye and See You Soon :)')\n",
    "                break\n",
    "            else:\n",
    "                clear_output(wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "SE = TwitterSearch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the desired number of results: 10\n",
      "Which mode would you like to use (insert number for the desired option)\n",
      "1: TF-IDF\n",
      "2: TF-IDF and authority\n",
      "2\n",
      "Enter your query: covid deaths england\n",
      "--> 1\n",
      "🇬🇧#coronavirus was the third most common cause of death in England and Wales in October.\n",
      "The Official for National Statistics has said 3,367 of the 43,265 deaths in England last month involved Covid. #WNM https://t.co/JZh6guAqvk  |  World News Media ALERT  |  2020-11-19 16:34:10+00:00  |  #coronavirus, #WNM  | Favorites:  0  | Retweets:  0  |  No url  | Followers:  115815\n",
      "\n",
      "\n",
      "--> 2\n",
      "England witnessed its highest death rate in over a decade in the year to end October as a result of the Covid pandemic, according to data released by the Office for National Statistics.  |  katniss  |  2020-11-19 15:54:38+00:00  |  No hashtags  | Favorites:  2  | Retweets:  0  |  No url  | Followers:  3950\n",
      "\n",
      "\n",
      "--> 3\n",
      "BBC reports that Covid was the third most common cause of death in October in England and Wales - behind dementia and heart disease  |  Robert Vinet 😷  |  2020-11-19 15:44:21+00:00  |  No hashtags  | Favorites:  0  | Retweets:  0  |  No url  | Followers:  2122\n",
      "\n",
      "\n",
      "--> 4\n",
      "Tributes pour in for mother of 13 who died of Covid. Sonia Partridge, 35, died in hospital as England registers highest death rate in a decade.\n",
      "\n",
      "   |  Helen121 🕷🐟  |  2020-11-19 16:50:25+00:00  |  No hashtags  | Favorites:  2  | Retweets:  2  |  https://t.co/3xK0AHwd0v  | Followers:  3679\n",
      "\n",
      "\n",
      "--> 5\n",
      "@haleemak_ I'm also a #COVID19 survivor still under the care of the NHS. So I'm very much top of covid news. I'm sending you actual news published stories over the last one week where people are talking about death rates especially in the North of England\n",
      "  |  Sohail Anjum  |  2020-11-19 16:20:35+00:00  |  #COVID19  | Favorites:  0  | Retweets:  0  |  https://t.co/yxCW4ElsZw  | Followers:  2501\n",
      "\n",
      "\n",
      "--> 6\n",
      "“What, the COVID deaths are going up despite a lockdown in England? Tell one BBC Radio station to censor Fairytale of New York and one not to. That will distract them!”  |  Sam Hutchings  |  2020-11-19 15:44:58+00:00  |  No hashtags  | Favorites:  0  | Retweets:  0  |  No url  | Followers:  1213\n",
      "\n",
      "\n",
      "--> 7\n",
      "@Megavolts001 Boris Johnson seems to be determined to destroy the economy. Sweden never imposed a national lockdown/mask wearing. Sweden has fewer COVID deaths per million than England. It's not because of population density, Stockholm has fewer deaths than Manchester (a similar size city).  |  Jeremy Hume  |  2020-11-19 17:01:03+00:00  |  No hashtags  | Favorites:  1  | Retweets:  0  |  No url  | Followers:  2676\n",
      "\n",
      "\n",
      "--> 8\n",
      "@emlio33 @pnjaban Still think over half of the deaths were forged to say Covid. My friends husband gets published in New England Medical Journal all the time. He is a doctor and says same thing. His colleagues around world say this as well.  They say maybe 40% were Covid deaths  |  President Elect Chris  |  2020-11-19 15:49:00+00:00  |  No hashtags  | Favorites:  0  | Retweets:  0  |  No url  | Followers:  321\n",
      "\n",
      "\n",
      "--> 9\n",
      "'England witnessed its highest death rate in over a decade in the year to the end of October as a result of the Covid pandemic'\n",
      "\n",
      "What this means, though, is that the age-standardised mortality rate was higher in every year 2001-2008 than in 2020.\n",
      "\n",
      "  |  gavinbailey  |  2020-11-19 17:40:36+00:00  |  No hashtags  | Favorites:  0  | Retweets:  0  |  https://t.co/0YGXveKiGq  | Followers:  577\n",
      "\n",
      "\n",
      "--> 10\n",
      "@BillyGrier @ScotNational If you’re using the excess death figures then England has had 70,000 deaths. \n",
      "\n",
      "Going by standard covid death statistics, 1,384 more people would have died if Scotland was under direct Tory rule. \n",
      "\n",
      "1,384 lives saved under devolution and the SNP  |  Caracalla  |  2020-11-19 16:04:52+00:00  |  No hashtags  | Favorites:  2  | Retweets:  1  |  No url  | Followers:  61\n",
      "\n",
      "\n",
      "Do you want to input another query [y/n]: n\n",
      "Stopping Search Engine... Good Bye and See You Soon :)\n"
     ]
    }
   ],
   "source": [
    "SE.interface()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Code.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
