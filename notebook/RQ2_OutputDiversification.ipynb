{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Question 2: Output Diversification\n",
    "\n",
    "## Important notes\n",
    "\n",
    "#### Download required files stored in Google Drive\n",
    "This script requires the file `inverted_index.json` and `tweets_with_authority.csv` that can be downloaded from the Google Drive Folder (`https://drive.google.com/drive/u/1/folders/16I4_ZCre59ufD9lDZbFK9cn1mALRmPjB`). The files must be stored in the `~/data` folder as specified in the README."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "sys.path.append('../')\n",
    "import pandas as pd\n",
    "from utils import *\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import Counter\n",
    "import json\n",
    "MODES = [1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_PATH = '../data/'\n",
    "AUTHORITY_DATASET = \"tweets_with_authority.csv\"\n",
    "INVERTED_INDEX = \"inverted_index.json\"\n",
    "VECTORIZER = \"vectorizer.pickle\"\n",
    "MODES = ['1', '2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwitterSearch:\n",
    "    def __init__(self):\n",
    "        self.data, self.corpus, self.vectorizer, self.inverted_index = self._load_information()\n",
    "\n",
    "    def _load_information(self):\n",
    "        # Load pretrained vectorizer\n",
    "        vectorizer = pickle.load(open(INPUT_PATH + 'vectorizer.pickle', \"rb\"))\n",
    "\n",
    "        # Load corpus\n",
    "        df = pd.read_csv(INPUT_PATH +'tweets_with_authority.csv')\n",
    "        corpus = df['clean_text']\n",
    "        corpus = corpus.fillna('')\n",
    "        corpus = vectorizer.transform(corpus)\n",
    "        \n",
    "        with open(INPUT_PATH + INVERTED_INDEX, 'r') as f:\n",
    "            inverted_index = json.load(f)\n",
    "\n",
    "        return df, corpus, vectorizer, inverted_index\n",
    "\n",
    "    def _get_tweet_fields(self, i):\n",
    "        \"\"\"\n",
    "        Returns the relevant fields for each tweet\n",
    "        i: id of the tweet we want to extract the information\n",
    "        returns various fields needed for showing the result to the user\n",
    "        \"\"\"\n",
    "        df = self.data\n",
    "        user_name = eval(df.iloc[i]['user'])['name']\n",
    "        text = df.iloc[i]['full_text']\n",
    "        entities = eval(df.iloc[i]['entities'])\n",
    "        urls = entities['urls']\n",
    "        if urls:\n",
    "            url = urls[0]['url']\n",
    "            text = text.replace(url, '')\n",
    "        else:\n",
    "            url = 'No url'\n",
    "\n",
    "        hashtags = entities['hashtags']\n",
    "\n",
    "        if not hashtags:\n",
    "            hashtags = 'No hashtags'\n",
    "\n",
    "        favorite_count = df.iloc[i]['favorite_count']\n",
    "        retweet_count = df.iloc[i]['retweet_count']\n",
    "        followers_count = df.iloc[i]['followers_count']\n",
    "\n",
    "        return user_name, text, url, hashtags, favorite_count, retweet_count, followers_count\n",
    "\n",
    "    def find_full_match_docs(self, query):\n",
    "        \"\"\"\n",
    "        Return the indexes of the documents containing all terms in the query\n",
    "        \"\"\"\n",
    "        docs = None\n",
    "\n",
    "        for word in query.split():\n",
    "            if docs is None:\n",
    "                docs = set([i[0] for i in self.inverted_index[word]])\n",
    "            else:\n",
    "                docs = docs.intersection(set([i[0] for i in self.inverted_index[word]]))\n",
    "        return list(self.data[self.data['id_str'].isin(docs)].index)\n",
    "\n",
    "    \n",
    "    def return_top_n_doc(self,query,n,show = True,authority = None):\n",
    "        \"\"\"\n",
    "        query: Query that the user writes.\n",
    "        tf_idf: dataframe containing tfidf weights for each word in each doc\n",
    "        n: number of doc to return to the user\n",
    "        show: if you want to visualize the results\n",
    "\n",
    "        returns a list with the most top n relevant tweets\n",
    "        \"\"\"\n",
    "        assert n>0, \"n should be a positive integer\"\n",
    "        query = clean_text(query) #noramalize the query\n",
    "        query_vec = self.vectorizer.transform([query]) #calculate tdidf\n",
    "        results = cosine_similarity(self.corpus, query_vec)\n",
    "        results = results.flatten()\n",
    "\n",
    "        documents_retrieved = []\n",
    "\n",
    "        #######Return the results#########\n",
    "        rank=0\n",
    "\n",
    "        if authority is not None:\n",
    "            results = 3*results*0.5*authority\n",
    "\n",
    "        # Reverse the results\n",
    "        results = results.argsort()[::-1]\n",
    "\n",
    "        ## Generate print mask for results\n",
    "\n",
    "        # The mask will contain the indexes from the results array in printing order\n",
    "        # By default this mask will be the first n results of our cosine similarity output\n",
    "        mask = [i for i in range(n)]\n",
    "\n",
    "        # We find those documents that contain all the terms in the query\n",
    "        full_matches = np.array(self.find_full_match_docs(query))\n",
    "\n",
    "        # If we have more full matches than desired results, we just use them in order to print\n",
    "        if len(full_matches)>=n:\n",
    "            mask = list(np.where(np.isin(results, full_matches))[0])\n",
    "\n",
    "        elif len(full_matches)==0:\n",
    "            pass    \n",
    "        # If not, we will include first those with full match and the remaining ones will be ordered\n",
    "        # simply by cosine similarity\n",
    "        else:\n",
    "            full_rank = 0\n",
    "\n",
    "            for i in range(len(results)):\n",
    "                if results[i] in full_matches:\n",
    "                    # Insert the full matches at the beggining to preserve the order of the remaining results\n",
    "                    mask.insert(full_rank, i) \n",
    "                    full_rank+=1\n",
    "\n",
    "        # Ensure we will only print n results\n",
    "        mask = mask[:n]\n",
    "\n",
    "        # Print following the order determined by the mask\n",
    "        for i in mask:\n",
    "            i = int(i)\n",
    "            user_name, text, url, hashtags, favorites, retweets, followers = self._get_tweet_fields(results[i])\n",
    "            if show == True:\n",
    "                print(\"-->\",rank + 1)\n",
    "                print(text,\" | \",user_name,\" | \",self.data.iloc[results[i]]['created_at'],\" | \", hashtags[:] ,\" | \",favorites,\" | \", retweets,\" | \",url, \" | \", followers)\n",
    "            \n",
    "            documents_retrieved.append(results[i])\n",
    "            rank +=1\n",
    "\n",
    "        return documents_retrieved\n",
    "\n",
    "    def query(self, query, n=20, authority=None):\n",
    "        self.return_top_n_doc(query, n, authority)\n",
    "\n",
    "    def interface(self):\n",
    "        while True:\n",
    "            n = int(input(\"Enter the desired number of results: \"))\n",
    "            assert n>0, \"The number of results must be a positive integer number\"\n",
    "            while True:\n",
    "                mode = str(input(\"\"\"Which mode would you like to use (insert number for the desired option)\\n1: TF-IDF\\n2: TF-IDF and authority\\n\"\"\"))\n",
    "                \n",
    "                if mode in MODES:\n",
    "                    break\n",
    "                else:\n",
    "                    print(\"Please insert some of these options: {}\".format(', '.join(MODES)))\n",
    "\n",
    "            query = input(\"Enter your query: \")\n",
    "            if mode == \"1\":\n",
    "                self.query(query, n)\n",
    "            elif mode == \"2\":\n",
    "                self.query(query, n, authority=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwitterSearch_Adapted(TwitterSearch):\n",
    "    def __init__(self,SAMPLE_SIZE):\n",
    "        self.data, self.corpus, self.vectorizer, self.inverted_index = self._load_information(SAMPLE_SIZE)\n",
    "\n",
    "    def _load_information(self, SAMPLE_SIZE): # We introduce a sample size\n",
    "        # Load pretrained vectorizer\n",
    "        vectorizer = pickle.load(open(INPUT_PATH + 'vectorizer.pickle', \"rb\"))\n",
    "\n",
    "        # Load corpus\n",
    "        df = pd.read_csv(INPUT_PATH +'tweets_with_authority.csv')[:SAMPLE_SIZE]\n",
    "        corpus = df['clean_text']\n",
    "        corpus = corpus.fillna('')\n",
    "        corpus = vectorizer.transform(corpus)\n",
    "        \n",
    "        with open(INPUT_PATH + INVERTED_INDEX, 'r') as f:\n",
    "            inverted_index = json.load(f)\n",
    "\n",
    "        return df, corpus, vectorizer, inverted_index\n",
    "    \n",
    "    def return_top_n_doc(self,query,n,c_labels = {},show = True, authority = None): # also returns clusters assigned to each doc\n",
    "        \"\"\"\n",
    "        query: Query that the user writes.\n",
    "        tf_idf: dataframe containing tfidf weights for each word in each doc\n",
    "        n: number of doc to return to the user\n",
    "        show: if you want to visualize the results\n",
    "\n",
    "        returns a list with the most top n relevant tweets\n",
    "        \"\"\"\n",
    "        assert n>0, \"n should be a positive integer\"\n",
    "        query = clean_text(query) #noramalize the query\n",
    "        query_vec = self.vectorizer.transform([query]) #calculate tdidf\n",
    "        results = cosine_similarity(self.corpus, query_vec)\n",
    "        results = results.flatten()\n",
    "\n",
    "        documents_retrieved = []\n",
    "\n",
    "        #######Return the results#########\n",
    "        rank=0\n",
    "\n",
    "        if authority is not None:\n",
    "            results = 3*results*0.5*authority\n",
    "            \n",
    "        similarities = results.copy()\n",
    "        sim_dict = {}\n",
    "        \n",
    "        max_similarity = results.max()\n",
    "\n",
    "        # Reverse the results\n",
    "        results = results.argsort()[::-1]\n",
    "\n",
    "        ## Generate print mask for results\n",
    "\n",
    "        # The mask will contain the indexes from the results array in printing order\n",
    "        # By default this mask will be the first n results of our cosine similarity output\n",
    "        mask = [i for i in range(n)]\n",
    "\n",
    "        # We find those documents that contain all the terms in the query\n",
    "        full_matches = np.array(self.find_full_match_docs(query))\n",
    "\n",
    "        # If we have more full matches than desired results, we just use them in order to print\n",
    "        if len(full_matches)>=n:\n",
    "            mask = list(np.where(np.isin(results, full_matches))[0])\n",
    "\n",
    "        elif len(full_matches)==0:\n",
    "            pass\n",
    "\n",
    "        # If not, we will include first those with full match and the remaining ones will be ordered\n",
    "        # simply by cosine similarity\n",
    "        else:\n",
    "            mask = [i for i in mask if results[i] not in full_matches]\n",
    "            full_rank = 0\n",
    "            for i in range(len(results)):\n",
    "                if results[i] in full_matches:\n",
    "                    # Insert the full matches at the beggining to preserve the order of the remaining results\n",
    "                    mask.insert(full_rank, i) \n",
    "                    full_rank+=1\n",
    "\n",
    "        # Ensure we will only print n results\n",
    "        mask = mask[:n]\n",
    "\n",
    "        # Print following the order determined by the mask\n",
    "        #Cluster representation list and rank\n",
    "        clusters_res = []\n",
    "        for i in mask:\n",
    "            i = int(i)\n",
    "            user_name, text, url, hashtags, favorites, retweets, followers = self._get_tweet_fields(results[i])\n",
    "            if show == True:\n",
    "                print(\"-->\", rank + 1)\n",
    "                print(text,\" | \",user_name,\" | \",self.data.iloc[results[i]]['created_at'],\" | \", hashtags[:] ,\" | \",favorites,\" | \", retweets,\" | \",url, \" | \", followers)\n",
    "            \n",
    "            documents_retrieved.append(results[i])\n",
    "            \n",
    "            # --- STORE SIMILARITY INFORMATION --- #\n",
    "            if rank<len(full_matches):\n",
    "                sim_dict[str(results[i])] = max_similarity+0.1*max_similarity*(1/(rank+1))\n",
    "            else:\n",
    "                sim_dict[str(results[i])] = similarities[results[i]]\n",
    "                \n",
    "            \n",
    "            #----OBTAIN CLUSTER INFORMATION----#\n",
    "            if c_labels:\n",
    "                c = c_labels[results[i]]\n",
    "                if show:\n",
    "                    print('Cluster:', c)\n",
    "                    print()\n",
    "\n",
    "                clusters_res.append(c)\n",
    "            \n",
    "            rank +=1\n",
    "            \n",
    "        return documents_retrieved, clusters_res, sim_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load cluster information from the previous research question RQ1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load clusters obtained in previous question RQ1\n",
    "load_file = INPUT_PATH + 'cluster_labels_docs_4_clusters.npy'\n",
    "c_labels = list(np.load(load_file))\n",
    "c_counts = Counter(c_labels)\n",
    "\n",
    "#Create a label dictionary for each doc\n",
    "l_dict = {}\n",
    "for i,l in enumerate(c_labels):\n",
    "    l_dict[i] = l\n",
    "    \n",
    "#COMPUTE probability of each cluster\n",
    "clusters = np.arange(0,len(c_counts.keys()))\n",
    "c_prob = []\n",
    "for i in clusters:\n",
    "    c_prob.append(c_counts[i]/len(c_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLUSTER PROBABILITIES = P(Vc)\n",
      "Cluster0 -> Prob: 0.301\n",
      "Cluster1 -> Prob: 0.256\n",
      "Cluster2 -> Prob: 0.281\n",
      "Cluster3 -> Prob: 0.163\n"
     ]
    }
   ],
   "source": [
    "print('CLUSTER PROBABILITIES = P(Vc)')\n",
    "for clus, prob in enumerate(c_prob):\n",
    "    print('Cluster{} -> Prob: {}'.format(clus,round(prob,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load tf idf and vectorizer information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = len(c_labels) #Sample Size used\n",
    "se = TwitterSearch_Adapted(SAMPLE_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain STANDARD RESULT of our SEARCH ENGINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Including similarity for rank 0 and doc 36902\n",
      "Including similarity for rank 1 and doc 36745\n",
      "Including similarity for rank 2 and doc 48625\n",
      "Including similarity for rank 3 and doc 4243\n",
      "Including similarity for rank 4 and doc 34212\n",
      "Including similarity for rank 5 and doc 54442\n",
      "Including similarity for rank 6 and doc 3858\n",
      "Including similarity for rank 7 and doc 2771\n",
      "Including similarity for rank 8 and doc 15523\n",
      "Including similarity for rank 9 and doc 39869\n",
      "Including similarity for rank 10 and doc 20507\n",
      "Including similarity for rank 11 and doc 23841\n",
      "Including similarity for rank 12 and doc 51879\n",
      "Including similarity for rank 13 and doc 45139\n",
      "Doc 5897\n",
      "Doc 6232\n",
      "Doc 35597\n",
      "Doc 25213\n",
      "Doc 6738\n",
      "Doc 47672\n"
     ]
    }
   ],
   "source": [
    "#query='Covid deaths England November'\n",
    "query='Problems with the vaccine'\n",
    "TOP = 20\n",
    "doc, clusters_std_res, sim_dict = se.return_top_n_doc(query,TOP,c_labels=l_dict,show=False, authority=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'36902': 0.7169270744023696,\n",
       " '36745': 0.6843394801113527,\n",
       " '48625': 0.6734769486810138,\n",
       " '4243': 0.6680456829658443,\n",
       " '34212': 0.6647869235367426,\n",
       " '54442': 0.6626144172506748,\n",
       " '3858': 0.6610626270463408,\n",
       " '2771': 0.6598987843930901,\n",
       " '15523': 0.6589935734405619,\n",
       " '39869': 0.6582694046785393,\n",
       " '20507': 0.6576769029641572,\n",
       " '23841': 0.6571831515355054,\n",
       " '51879': 0.6567653618651078,\n",
       " '45139': 0.6564072564333383,\n",
       " '5897': 0.6517518858203359,\n",
       " '6232': 0.6517518858203359,\n",
       " '35597': 0.5849219261196236,\n",
       " '25213': 0.5667250240087351,\n",
       " '6738': 0.5667250240087351,\n",
       " '47672': 0.5667250240087351}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RE-RANKING ALGORITHM TAKING INTO ACCOUNT FAIRNESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FAIRNESS_Re_Ranking(TwitterSearch_Adapted):\n",
    "    def __init__(self, doc_set,sim_dict, c_prob, c_labels,lambda_value, Fair_rank_size,SAMPLE_SIZE):\n",
    "            self.doc_set = doc_set\n",
    "            self.sim_dict = sim_dict\n",
    "            self.l_dict = c_labels\n",
    "            self.Rank_size = Fair_rank_size\n",
    "            self.c_prob = c_prob\n",
    "            self.lambda_value = lambda_value\n",
    "            self.fair_set = []\n",
    "            self.clusters_res = []\n",
    "            self.SAMPLE_SIZE = SAMPLE_SIZE\n",
    "            \n",
    "    def fairness_in_res(self, doc_cluster):\n",
    "        #if a cluster is already in the set this wil be 0\n",
    "\n",
    "        fair_set_clusters = [self.l_dict[doc] for doc in self.fair_set] #calculate the clusters represented in the fair set\n",
    "        cluster_representation = Counter(fair_set_clusters)\n",
    "        # If a cluster not represented return 1, else return 0\n",
    "        if len(self.fair_set) < len(set(self.l_dict.items())): #While not all clusters represented use the algorithm proposed\n",
    "            if doc_cluster in fair_set_clusters:\n",
    "                return 0\n",
    "            else:\n",
    "                return 1\n",
    "        else:\n",
    "            percentage_cluster = cluster_representation[doc_cluster]/len(self.fair_set)\n",
    "\n",
    "            return (1 - percentage_cluster)\n",
    "\n",
    "    def fairness_score(self, doc_index):\n",
    "        #Compute the fairness for the cluster where the document belongs\n",
    "        #We are assuming that a document can only belong to one cluster\n",
    "        document_cluster = self.l_dict[doc_index]\n",
    "        f_score = self.c_prob[document_cluster] * self.fairness_in_res(document_cluster)\n",
    "        return f_score\n",
    "    \n",
    "    def compute_diversity_score(self):\n",
    "        '''\n",
    "        INPUTS:\n",
    "        doc_set = R(u)\n",
    "        sim_dict : Equivalent to results matrix obtained in return_top_n_doc P(v|u)\n",
    "        cluster_prob: Prior probabilities of each cluster. P(Vc)\n",
    "        lam = value for the lambda\n",
    "        '''\n",
    "        div_score = [] #List of diversity scores for each document in the R(u) set\n",
    "        f_score = 0\n",
    "        for doc_index in self.doc_set:\n",
    "            similarity_measure = (1-self.lambda_value) * self.sim_dict[str(doc_index)] #P(v|u) = similarity (in our case definition)\n",
    "            f_score = self.lambda_value * self.fairness_score(doc_index)\n",
    "            div_score.append(similarity_measure + f_score)\n",
    "        doc_more_fair = np.argmax(div_score)\n",
    "        return self.doc_set[doc_more_fair], div_score\n",
    "    \n",
    "    def print_results(self,print_labels = True,show = True):\n",
    "        #print the documents contained in docs\n",
    "        if show:\n",
    "            self.data, self.corpus, self.vectorizer, self.inverted_index = self._load_information(SAMPLE_SIZE)\n",
    "        for rank, doc in enumerate(self.fair_set):\n",
    "            if show:\n",
    "                user_name, text, url, hashtags, favorites, retweets, followers = self._get_tweet_fields(doc)\n",
    "                print(\"{} -- User: {} ({} followers) | RT: {} | FAV: {}\".format(rank+1, user_name, followers, retweets, favorites))\n",
    "                print(\"-------------------------\")\n",
    "                print(\"text:\",text)\n",
    "                print(\"-------------------------\")\n",
    "            if print_labels:\n",
    "                c = self.l_dict[doc]\n",
    "                if show:\n",
    "                    print('Cluster:',c)\n",
    "                    print()\n",
    "                self.clusters_res.append(c)\n",
    "            rank +=1\n",
    "    \n",
    "    def Re_Ranking_Fairness(self, print_labels = True,show=True):\n",
    "        #initialized R(u) = doc_set, and S(u)= fari_set\n",
    "        #RUN RE RANK ALGORITHM\n",
    "        for i in range(0,self.Rank_size):\n",
    "            doc_more_fair, div_score = self.compute_diversity_score()\n",
    "            self.fair_set.append(doc_more_fair)\n",
    "            self.doc_set.remove(doc_more_fair)\n",
    "            \n",
    "        self.print_results(print_labels,show)\n",
    "        #return fair_set,cluster_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_set = doc.copy()\n",
    "lambda_val = 0.8\n",
    "Rank_size = 10\n",
    "FAIR_RANK = FAIRNESS_Re_Ranking(doc_set, sim_dict, c_prob,l_dict,lambda_val,Rank_size,SAMPLE_SIZE)\n",
    "FAIR_RANK.Re_Ranking_Fairness(show=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clutsers obtained in the two results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_clusters_in_result(doc,clusters_std_res,top = None,title = 'STANDARD SEARCH ENGINE'):\n",
    "    if top:\n",
    "        doc = doc[:top]\n",
    "        clusters_std_res = clusters_std_res[:top]\n",
    "    counter = Counter(clusters_std_res)\n",
    "    print('Cluster Representation in ' + title)\n",
    "    print('Total clusters represented = {}'.format(len(counter.keys())))\n",
    "    print('Clusters coverage = {}'.format(counter))\n",
    "    print()\n",
    "    rank = 0\n",
    "    for d,clust in zip(doc,clusters_std_res):\n",
    "        print('{} >> Document {}, C {}'.format(rank+1,d,clust))\n",
    "        rank += 1\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Representation in STANDARD SEARCH ENGINE\n",
      "Total clusters represented = 4\n",
      "Clusters coverage = Counter({0: 4, 1: 3, 2: 2, 3: 1})\n",
      "\n",
      "1 >> Document 51128, C 0\n",
      "2 >> Document 48813, C 0\n",
      "3 >> Document 903, C 2\n",
      "4 >> Document 25038, C 1\n",
      "5 >> Document 54941, C 2\n",
      "6 >> Document 17968, C 1\n",
      "7 >> Document 7100, C 0\n",
      "8 >> Document 11378, C 0\n",
      "9 >> Document 50948, C 1\n",
      "10 >> Document 30734, C 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_clusters_in_result(doc,clusters_std_res,top =FAIR_RANK.Rank_size,title = 'STANDARD SEARCH ENGINE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Representation in RE-RANKED FAIR RESULTS\n",
      "Total clusters represented = 4\n",
      "Clusters coverage = Counter({0: 3, 1: 3, 3: 3, 2: 1})\n",
      "\n",
      "1 >> Document 903, C 0\n",
      "2 >> Document 36439, C 2\n",
      "3 >> Document 48813, C 1\n",
      "4 >> Document 51128, C 3\n",
      "5 >> Document 25038, C 3\n",
      "6 >> Document 54941, C 0\n",
      "7 >> Document 17968, C 0\n",
      "8 >> Document 7100, C 3\n",
      "9 >> Document 11378, C 1\n",
      "10 >> Document 50948, C 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_clusters_in_result(FAIR_RANK.fair_set,FAIR_RANK.clusters_res,top = None,title = 'RE-RANKED FAIR RESULTS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COMPUTING CORRELATION BETWEEN RANKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SPEARMANS CORRELATION: Intuitively, the Spearman correlation between two variables will be high when observations have a similar (or identical for a correlation of 1) rank (i.e. relative position label of the observations within the variable: 1st, 2nd, 3rd, etc.) between the two variables, and low when observations have a dissimilar (or fully opposed for a correlation of −1) rank between the two variables.\n",
    "\n",
    "KENDALL CORRELATION: Intuitively, the Kendall correlation between two variables will be high when observations have a similar (or identical for a correlation of 1) rank (i.e. relative position label of the observations within the variable: 1st, 2nd, 3rd, etc.) between the two variables, and low when observations have a dissimilar (or fully different for a correlation of −1) rank between the two variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "query_list = ['Why does trump not wear a mask?',\n",
    "              'News from covid',\n",
    "              'When will the covid vaccine be available?',\n",
    "              'How many people has died from covid?',\n",
    "              'Covid deaths england November',\n",
    "              'Covid total number of tests',\n",
    "              'What does trump say about covid?',\n",
    "              'Covid impact Amazon company',\n",
    "              'Covid vaccine trials',\n",
    "              'Covid death rate'\n",
    "              ]\n",
    "\n",
    "#### -------HYPERPARAMETER SET------------------\n",
    "SEARCH_SPACE = 20\n",
    "TOP  = 10\n",
    "Fair_Rank_size = 10\n",
    "lambda_value = 0.9\n",
    "SAMPLE_SIZE = len(c_labels) #Sample Size used\n",
    "\n",
    "se = TwitterSearch_Adapted(SAMPLE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query >>  Why does trump not wear a mask?\n",
      "Cluster Representation in STANDARD SEARCH ENGINE\n",
      "Total clusters represented = 3\n",
      "Clusters coverage = Counter({2: 4, 1: 4, 0: 2})\n",
      "\n",
      "1 >> Document 20321, C 2\n",
      "2 >> Document 1361, C 1\n",
      "3 >> Document 26351, C 2\n",
      "4 >> Document 8639, C 0\n",
      "5 >> Document 33784, C 1\n",
      "6 >> Document 27478, C 1\n",
      "7 >> Document 160, C 1\n",
      "8 >> Document 46591, C 0\n",
      "9 >> Document 30887, C 2\n",
      "10 >> Document 41103, C 2\n",
      "\n",
      "Cluster Representation in FAIR SEARCH ENGINE\n",
      "Total clusters represented = 4\n",
      "Clusters coverage = Counter({1: 4, 2: 3, 0: 2, 3: 1})\n",
      "\n",
      "1 >> Document 8639, C 0\n",
      "2 >> Document 20321, C 2\n",
      "3 >> Document 1361, C 1\n",
      "4 >> Document 12203, C 3\n",
      "5 >> Document 26351, C 2\n",
      "6 >> Document 33784, C 1\n",
      "7 >> Document 27478, C 1\n",
      "8 >> Document 160, C 1\n",
      "9 >> Document 46591, C 0\n",
      "10 >> Document 30887, C 2\n",
      "\n",
      "----RANKS OBTAINED------\n",
      "Not Fair:  [41103, 11010, 42470, 41499, 42314, 18951, 32964, 31013, 52266, 49386]\n",
      "Fair:      [8639, 20321, 1361, 12203, 26351, 33784, 27478, 160, 46591, 30887]\n",
      "Spearmans Rank Correlation 0.25 and p_value 0.49.\n",
      "Kendalls Rank Correlation 0.2 and p_value 0.48.\n",
      "\n",
      "Query >>  News from covid\n",
      "Cluster Representation in STANDARD SEARCH ENGINE\n",
      "Total clusters represented = 4\n",
      "Clusters coverage = Counter({1: 4, 0: 2, 3: 2, 2: 2})\n",
      "\n",
      "1 >> Document 54298, C 0\n",
      "2 >> Document 54321, C 1\n",
      "3 >> Document 45943, C 1\n",
      "4 >> Document 54596, C 0\n",
      "5 >> Document 38533, C 3\n",
      "6 >> Document 40335, C 2\n",
      "7 >> Document 53145, C 1\n",
      "8 >> Document 9463, C 3\n",
      "9 >> Document 24220, C 1\n",
      "10 >> Document 30878, C 2\n",
      "\n",
      "Cluster Representation in FAIR SEARCH ENGINE\n",
      "Total clusters represented = 4\n",
      "Clusters coverage = Counter({1: 4, 0: 2, 2: 2, 3: 2})\n",
      "\n",
      "1 >> Document 54298, C 0\n",
      "2 >> Document 40335, C 2\n",
      "3 >> Document 54321, C 1\n",
      "4 >> Document 38533, C 3\n",
      "5 >> Document 45943, C 1\n",
      "6 >> Document 54596, C 0\n",
      "7 >> Document 53145, C 1\n",
      "8 >> Document 9463, C 3\n",
      "9 >> Document 24220, C 1\n",
      "10 >> Document 30878, C 2\n",
      "\n",
      "----RANKS OBTAINED------\n",
      "Not Fair:  [16394, 12339, 50303, 16189, 29320, 49781, 9296, 31878, 6932, 44406]\n",
      "Fair:      [54298, 40335, 54321, 38533, 45943, 54596, 53145, 9463, 24220, 30878]\n",
      "Spearmans Rank Correlation 0.38 and p_value 0.28.\n",
      "Kendalls Rank Correlation 0.24 and p_value 0.38.\n",
      "\n",
      "Query >>  When will the covid vaccine be available?\n",
      "Cluster Representation in STANDARD SEARCH ENGINE\n",
      "Total clusters represented = 4\n",
      "Clusters coverage = Counter({0: 3, 3: 3, 2: 2, 1: 2})\n",
      "\n",
      "1 >> Document 2243, C 2\n",
      "2 >> Document 8275, C 1\n",
      "3 >> Document 35653, C 0\n",
      "4 >> Document 51635, C 0\n",
      "5 >> Document 27079, C 3\n",
      "6 >> Document 5214, C 1\n",
      "7 >> Document 11010, C 0\n",
      "8 >> Document 42881, C 3\n",
      "9 >> Document 1606, C 2\n",
      "10 >> Document 20136, C 3\n",
      "\n",
      "Cluster Representation in FAIR SEARCH ENGINE\n",
      "Total clusters represented = 4\n",
      "Clusters coverage = Counter({0: 3, 3: 3, 2: 2, 1: 2})\n",
      "\n",
      "1 >> Document 35653, C 0\n",
      "2 >> Document 2243, C 2\n",
      "3 >> Document 8275, C 1\n",
      "4 >> Document 27079, C 3\n",
      "5 >> Document 51635, C 0\n",
      "6 >> Document 5214, C 1\n",
      "7 >> Document 11010, C 0\n",
      "8 >> Document 42881, C 3\n",
      "9 >> Document 1606, C 2\n",
      "10 >> Document 20136, C 3\n",
      "\n",
      "----RANKS OBTAINED------\n",
      "Not Fair:  [49657, 23940, 40443, 24994, 23717, 23916, 16054, 9959, 42336, 31284]\n",
      "Fair:      [35653, 2243, 8275, 27079, 51635, 5214, 11010, 42881, 1606, 20136]\n",
      "Spearmans Rank Correlation -0.32 and p_value 0.37.\n",
      "Kendalls Rank Correlation -0.24 and p_value 0.38.\n",
      "\n",
      "Query >>  How many people has died from covid?\n",
      "Cluster Representation in STANDARD SEARCH ENGINE\n",
      "Total clusters represented = 4\n",
      "Clusters coverage = Counter({0: 3, 2: 3, 1: 2, 3: 2})\n",
      "\n",
      "1 >> Document 7079, C 0\n",
      "2 >> Document 27632, C 1\n",
      "3 >> Document 40735, C 2\n",
      "4 >> Document 35734, C 0\n",
      "5 >> Document 40922, C 0\n",
      "6 >> Document 37273, C 1\n",
      "7 >> Document 47065, C 2\n",
      "8 >> Document 50699, C 3\n",
      "9 >> Document 41025, C 2\n",
      "10 >> Document 9553, C 3\n",
      "\n",
      "Cluster Representation in FAIR SEARCH ENGINE\n",
      "Total clusters represented = 4\n",
      "Clusters coverage = Counter({0: 3, 2: 3, 1: 2, 3: 2})\n",
      "\n",
      "1 >> Document 7079, C 0\n",
      "2 >> Document 40735, C 2\n",
      "3 >> Document 27632, C 1\n",
      "4 >> Document 50699, C 3\n",
      "5 >> Document 35734, C 0\n",
      "6 >> Document 40922, C 0\n",
      "7 >> Document 37273, C 1\n",
      "8 >> Document 47065, C 2\n",
      "9 >> Document 41025, C 2\n",
      "10 >> Document 9553, C 3\n",
      "\n",
      "----RANKS OBTAINED------\n",
      "Not Fair:  [50861, 17906, 52797, 26465, 48601, 49806, 28581, 31157, 12138, 45494]\n",
      "Fair:      [7079, 40735, 27632, 50699, 35734, 40922, 37273, 47065, 41025, 9553]\n",
      "Spearmans Rank Correlation -0.64 and p_value 0.05.\n",
      "Kendalls Rank Correlation -0.47 and p_value 0.07.\n",
      "\n",
      "Query >>  Covid deaths england November\n",
      "Cluster Representation in STANDARD SEARCH ENGINE\n",
      "Total clusters represented = 4\n",
      "Clusters coverage = Counter({2: 5, 3: 2, 1: 2, 0: 1})\n",
      "\n",
      "1 >> Document 27981, C 2\n",
      "2 >> Document 42479, C 2\n",
      "3 >> Document 40426, C 2\n",
      "4 >> Document 6962, C 2\n",
      "5 >> Document 11399, C 2\n",
      "6 >> Document 17401, C 3\n",
      "7 >> Document 39186, C 1\n",
      "8 >> Document 27739, C 1\n",
      "9 >> Document 41485, C 0\n",
      "10 >> Document 48440, C 3\n",
      "\n",
      "Cluster Representation in FAIR SEARCH ENGINE\n",
      "Total clusters represented = 4\n",
      "Clusters coverage = Counter({2: 5, 1: 2, 3: 2, 0: 1})\n",
      "\n",
      "1 >> Document 41485, C 0\n",
      "2 >> Document 27981, C 2\n",
      "3 >> Document 39186, C 1\n",
      "4 >> Document 17401, C 3\n",
      "5 >> Document 42479, C 2\n",
      "6 >> Document 40426, C 2\n",
      "7 >> Document 6962, C 2\n",
      "8 >> Document 11399, C 2\n",
      "9 >> Document 27739, C 1\n",
      "10 >> Document 48440, C 3\n",
      "\n",
      "----RANKS OBTAINED------\n",
      "Not Fair:  [16688, 13826, 20039, 50388, 35566, 1035, 947, 37154, 20323, 45200]\n",
      "Fair:      [41485, 27981, 39186, 17401, 42479, 40426, 6962, 11399, 27739, 48440]\n",
      "Spearmans Rank Correlation 0.15 and p_value 0.68.\n",
      "Kendalls Rank Correlation 0.11 and p_value 0.73.\n",
      "\n",
      "Query >>  Covid total number of tests\n",
      "Cluster Representation in STANDARD SEARCH ENGINE\n",
      "Total clusters represented = 3\n",
      "Clusters coverage = Counter({2: 5, 3: 3, 1: 2})\n",
      "\n",
      "1 >> Document 1699, C 3\n",
      "2 >> Document 28712, C 2\n",
      "3 >> Document 16106, C 2\n",
      "4 >> Document 5600, C 3\n",
      "5 >> Document 42748, C 1\n",
      "6 >> Document 12180, C 2\n",
      "7 >> Document 11074, C 3\n",
      "8 >> Document 33046, C 2\n",
      "9 >> Document 31764, C 1\n",
      "10 >> Document 34579, C 2\n",
      "\n",
      "Cluster Representation in FAIR SEARCH ENGINE\n",
      "Total clusters represented = 4\n",
      "Clusters coverage = Counter({2: 4, 3: 3, 1: 2, 0: 1})\n",
      "\n",
      "1 >> Document 36004, C 0\n",
      "2 >> Document 28712, C 2\n",
      "3 >> Document 42748, C 1\n",
      "4 >> Document 1699, C 3\n",
      "5 >> Document 16106, C 2\n",
      "6 >> Document 5600, C 3\n",
      "7 >> Document 12180, C 2\n",
      "8 >> Document 11074, C 3\n",
      "9 >> Document 33046, C 2\n",
      "10 >> Document 31764, C 1\n",
      "\n",
      "----RANKS OBTAINED------\n",
      "Not Fair:  [34579, 43008, 54175, 23438, 36877, 29581, 5999, 12640, 53043, 41097]\n",
      "Fair:      [36004, 28712, 42748, 1699, 16106, 5600, 12180, 11074, 33046, 31764]\n",
      "Spearmans Rank Correlation 0.76 and p_value 0.01.\n",
      "Kendalls Rank Correlation 0.56 and p_value 0.03.\n",
      "\n",
      "Query >>  What does trump say about covid?\n",
      "Cluster Representation in STANDARD SEARCH ENGINE\n",
      "Total clusters represented = 3\n",
      "Clusters coverage = Counter({1: 5, 0: 4, 2: 1})\n",
      "\n",
      "1 >> Document 15259, C 0\n",
      "2 >> Document 23871, C 1\n",
      "3 >> Document 51238, C 0\n",
      "4 >> Document 36829, C 2\n",
      "5 >> Document 36943, C 1\n",
      "6 >> Document 34225, C 1\n",
      "7 >> Document 37889, C 1\n",
      "8 >> Document 34467, C 0\n",
      "9 >> Document 34758, C 1\n",
      "10 >> Document 34822, C 0\n",
      "\n",
      "Cluster Representation in FAIR SEARCH ENGINE\n",
      "Total clusters represented = 4\n",
      "Clusters coverage = Counter({1: 5, 0: 3, 2: 1, 3: 1})\n",
      "\n",
      "1 >> Document 15259, C 0\n",
      "2 >> Document 36829, C 2\n",
      "3 >> Document 23871, C 1\n",
      "4 >> Document 35894, C 3\n",
      "5 >> Document 51238, C 0\n",
      "6 >> Document 36943, C 1\n",
      "7 >> Document 34225, C 1\n",
      "8 >> Document 37889, C 1\n",
      "9 >> Document 34467, C 0\n",
      "10 >> Document 34758, C 1\n",
      "\n",
      "----RANKS OBTAINED------\n",
      "Not Fair:  [34822, 35755, 35824, 34897, 34405, 36727, 37976, 4516, 2181, 3771]\n",
      "Fair:      [15259, 36829, 23871, 35894, 51238, 36943, 34225, 37889, 34467, 34758]\n",
      "Spearmans Rank Correlation -0.16 and p_value 0.65.\n",
      "Kendalls Rank Correlation -0.02 and p_value 1.0.\n",
      "\n",
      "Query >>  Covid impact Amazon company\n",
      "Cluster Representation in STANDARD SEARCH ENGINE\n",
      "Total clusters represented = 4\n",
      "Clusters coverage = Counter({2: 3, 3: 3, 1: 3, 0: 1})\n",
      "\n",
      "1 >> Document 53429, C 2\n",
      "2 >> Document 53290, C 3\n",
      "3 >> Document 53015, C 0\n",
      "4 >> Document 1402, C 2\n",
      "5 >> Document 41960, C 3\n",
      "6 >> Document 6208, C 1\n",
      "7 >> Document 9743, C 1\n",
      "8 >> Document 3876, C 3\n",
      "9 >> Document 16283, C 1\n",
      "10 >> Document 6787, C 2\n",
      "\n",
      "Cluster Representation in FAIR SEARCH ENGINE\n",
      "Total clusters represented = 4\n",
      "Clusters coverage = Counter({2: 3, 1: 3, 3: 3, 0: 1})\n",
      "\n",
      "1 >> Document 53015, C 0\n",
      "2 >> Document 53429, C 2\n",
      "3 >> Document 6208, C 1\n",
      "4 >> Document 53290, C 3\n",
      "5 >> Document 1402, C 2\n",
      "6 >> Document 41960, C 3\n",
      "7 >> Document 9743, C 1\n",
      "8 >> Document 3876, C 3\n",
      "9 >> Document 16283, C 1\n",
      "10 >> Document 6787, C 2\n",
      "\n",
      "----RANKS OBTAINED------\n",
      "Not Fair:  [11062, 52468, 40162, 95, 0, 49554, 5017, 32993, 34208, 24894]\n",
      "Fair:      [53015, 53429, 6208, 53290, 1402, 41960, 9743, 3876, 16283, 6787]\n",
      "Spearmans Rank Correlation 0.3 and p_value 0.4.\n",
      "Kendalls Rank Correlation 0.2 and p_value 0.48.\n",
      "\n",
      "Query >>  Covid vaccine trials\n",
      "Cluster Representation in STANDARD SEARCH ENGINE\n",
      "Total clusters represented = 3\n",
      "Clusters coverage = Counter({2: 4, 1: 3, 3: 3})\n",
      "\n",
      "1 >> Document 31813, C 2\n",
      "2 >> Document 12091, C 1\n",
      "3 >> Document 8295, C 1\n",
      "4 >> Document 36533, C 2\n",
      "5 >> Document 11768, C 2\n",
      "6 >> Document 53028, C 3\n",
      "7 >> Document 39074, C 3\n",
      "8 >> Document 34161, C 2\n",
      "9 >> Document 8201, C 1\n",
      "10 >> Document 15464, C 3\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Representation in FAIR SEARCH ENGINE\n",
      "Total clusters represented = 4\n",
      "Clusters coverage = Counter({2: 4, 1: 3, 3: 2, 0: 1})\n",
      "\n",
      "1 >> Document 857, C 0\n",
      "2 >> Document 31813, C 2\n",
      "3 >> Document 12091, C 1\n",
      "4 >> Document 53028, C 3\n",
      "5 >> Document 8295, C 1\n",
      "6 >> Document 36533, C 2\n",
      "7 >> Document 11768, C 2\n",
      "8 >> Document 39074, C 3\n",
      "9 >> Document 34161, C 2\n",
      "10 >> Document 8201, C 1\n",
      "\n",
      "----RANKS OBTAINED------\n",
      "Not Fair:  [15464, 5021, 35935, 18581, 18097, 10025, 29036, 27382, 33510, 37902]\n",
      "Fair:      [857, 31813, 12091, 53028, 8295, 36533, 11768, 39074, 34161, 8201]\n",
      "Spearmans Rank Correlation -0.15 and p_value 0.68.\n",
      "Kendalls Rank Correlation -0.11 and p_value 0.73.\n",
      "\n",
      "Query >>  Covid death rate\n",
      "Cluster Representation in STANDARD SEARCH ENGINE\n",
      "Total clusters represented = 3\n",
      "Clusters coverage = Counter({1: 4, 3: 3, 0: 3})\n",
      "\n",
      "1 >> Document 51128, C 3\n",
      "2 >> Document 48813, C 1\n",
      "3 >> Document 903, C 0\n",
      "4 >> Document 25038, C 3\n",
      "5 >> Document 54941, C 0\n",
      "6 >> Document 17968, C 0\n",
      "7 >> Document 7100, C 3\n",
      "8 >> Document 11378, C 1\n",
      "9 >> Document 50948, C 1\n",
      "10 >> Document 30734, C 1\n",
      "\n",
      "Cluster Representation in FAIR SEARCH ENGINE\n",
      "Total clusters represented = 4\n",
      "Clusters coverage = Counter({0: 3, 1: 3, 3: 3, 2: 1})\n",
      "\n",
      "1 >> Document 903, C 0\n",
      "2 >> Document 36439, C 2\n",
      "3 >> Document 48813, C 1\n",
      "4 >> Document 51128, C 3\n",
      "5 >> Document 25038, C 3\n",
      "6 >> Document 54941, C 0\n",
      "7 >> Document 17968, C 0\n",
      "8 >> Document 7100, C 3\n",
      "9 >> Document 11378, C 1\n",
      "10 >> Document 50948, C 1\n",
      "\n",
      "----RANKS OBTAINED------\n",
      "Not Fair:  [30734, 30172, 29179, 48818, 9406, 4194, 27867, 52028, 15416, 44834]\n",
      "Fair:      [903, 36439, 48813, 51128, 25038, 54941, 17968, 7100, 11378, 50948]\n",
      "Spearmans Rank Correlation -0.18 and p_value 0.63.\n",
      "Kendalls Rank Correlation -0.07 and p_value 0.86.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for query in query_list:\n",
    "    print('Query >> ',query)\n",
    "    \n",
    "    doc,clusters_notfair, sim_dict = se.return_top_n_doc(query,SEARCH_SPACE,c_labels=l_dict,show=False, authority=None)\n",
    "    \n",
    "    doc_not_fair = doc.copy()\n",
    "    \n",
    "    print_clusters_in_result(doc,clusters_notfair,TOP)\n",
    "    \n",
    "    FAIR_RANK = FAIRNESS_Re_Ranking(doc_not_fair,sim_dict,c_prob,l_dict,lambda_value,Fair_Rank_size,SAMPLE_SIZE)\n",
    "    FAIR_RANK.Re_Ranking_Fairness(print_labels = True,show = False)\n",
    "    \n",
    "    corr, p_value = stats.spearmanr(doc_not_fair[:FAIR_RANK.Rank_size],FAIR_RANK.fair_set)\n",
    "    tau, p_value_k = stats.kendalltau(doc_not_fair[:FAIR_RANK.Rank_size],FAIR_RANK.fair_set)\n",
    "    \n",
    "    print_clusters_in_result(FAIR_RANK.fair_set,FAIR_RANK.clusters_res,FAIR_RANK.Rank_size,title='FAIR SEARCH ENGINE')\n",
    "\n",
    "    print('----RANKS OBTAINED------')\n",
    "    print('Not Fair: ', doc_not_fair[:FAIR_RANK.Rank_size])\n",
    "    print('Fair:     ',FAIR_RANK.fair_set )\n",
    "    print('Spearmans Rank Correlation {} and p_value {}.'.format(np.round(corr,2),np.round(p_value,2)))\n",
    "    print('Kendalls Rank Correlation {} and p_value {}.'.format(np.round(tau,2),np.round(p_value_k,2)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
