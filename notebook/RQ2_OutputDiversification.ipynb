{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RQ2: Output Diversification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "sys.path.append('../')\n",
    "import pandas as pd\n",
    "\n",
    "from utils import clean_text\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import Counter\n",
    "import json\n",
    "MODES = [1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_PATH = './DATA_RQ2/'\n",
    "AUTHORITY_DATASET = \"tweets_with_authority.csv\"\n",
    "INVERTED_INDEX = \"inverted_index.json\"\n",
    "VECTORIZER = \"vectorizer.pickle\"\n",
    "MODES = ['1', '2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def personalized_tokenizer(text):\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwitterSearch:\n",
    "    def __init__(self):\n",
    "        self.data, self.corpus, self.vectorizer, self.inverted_index = self._load_information()\n",
    "\n",
    "    def _load_information(self):\n",
    "        # Load pretrained vectorizer\n",
    "        vectorizer = pickle.load(open(INPUT_PATH + 'vectorizer.pickle', \"rb\"))\n",
    "\n",
    "        # Load corpus\n",
    "        df = pd.read_csv(INPUT_PATH +'tweets_with_authority.csv')\n",
    "        corpus = df['clean_text']\n",
    "        corpus = corpus.fillna('')\n",
    "        corpus = vectorizer.transform(corpus)\n",
    "        \n",
    "        with open(INPUT_PATH + INVERTED_INDEX, 'r') as f:\n",
    "            inverted_index = json.load(f)\n",
    "\n",
    "        return df, corpus, vectorizer, inverted_index\n",
    "\n",
    "    def _get_tweet_fields(self, i):\n",
    "        \"\"\"\n",
    "        Returns the relevant fields for each tweet\n",
    "        i: id of the tweet we want to extract the information\n",
    "        returns various fields needed for showing the result to the user\n",
    "        \"\"\"\n",
    "        df = self.data\n",
    "        user_name = eval(df.iloc[i]['user'])['name']\n",
    "        text = df.iloc[i]['full_text']\n",
    "        entities = eval(df.iloc[i]['entities'])\n",
    "        urls = entities['urls']\n",
    "        if urls:\n",
    "            url = urls[0]['url']\n",
    "            text = text.replace(url, '')\n",
    "        else:\n",
    "            url = 'No url'\n",
    "\n",
    "        hashtags = entities['hashtags']\n",
    "\n",
    "        if not hashtags:\n",
    "            hashtags = 'No hashtags'\n",
    "\n",
    "        favorite_count = df.iloc[i]['favorite_count']\n",
    "        retweet_count = df.iloc[i]['retweet_count']\n",
    "        followers_count = df.iloc[i]['followers_count']\n",
    "\n",
    "        return user_name, text, url, hashtags, favorite_count, retweet_count, followers_count\n",
    "\n",
    "    def find_full_match_docs(self, query):\n",
    "        \"\"\"\n",
    "        Return the indexes of the documents containing all terms in the query\n",
    "        \"\"\"\n",
    "        docs = None\n",
    "\n",
    "        for word in query.split():\n",
    "            if docs is None:\n",
    "                docs = set([i[0] for i in self.inverted_index[word]])\n",
    "            else:\n",
    "                docs = docs.intersection(set([i[0] for i in self.inverted_index[word]]))\n",
    "        return list(self.data[self.data['id_str'].isin(docs)].index)\n",
    "\n",
    "    \n",
    "    def return_top_n_doc(self,query,n,show = True,authority = None):\n",
    "        \"\"\"\n",
    "        query: Query that the user writes.\n",
    "        tf_idf: dataframe containing tfidf weights for each word in each doc\n",
    "        n: number of doc to return to the user\n",
    "        show: if you want to visualize the results\n",
    "\n",
    "        returns a list with the most top n relevant tweets\n",
    "        \"\"\"\n",
    "        assert n>0, \"n should be a positive integer\"\n",
    "        query = clean_text(query) #noramalize the query\n",
    "        query_vec = self.vectorizer.transform([query]) #calculate tdidf\n",
    "        results = cosine_similarity(self.corpus, query_vec)\n",
    "        results = results.flatten()\n",
    "\n",
    "        documents_retrieved = []\n",
    "\n",
    "        #######Return the results#########\n",
    "        rank=0\n",
    "\n",
    "        if authority is not None:\n",
    "            results = 3*results*0.5*authority\n",
    "\n",
    "        # Reverse the results\n",
    "        results = results.argsort()[::-1]\n",
    "\n",
    "        ## Generate print mask for results\n",
    "\n",
    "        # The mask will contain the indexes from the results array in printing order\n",
    "        # By default this mask will be the first n results of our cosine similarity output\n",
    "        mask = [i for i in range(n)]\n",
    "\n",
    "        # We find those documents that contain all the terms in the query\n",
    "        full_matches = np.array(self.find_full_match_docs(query))\n",
    "\n",
    "        # If we have more full matches than desired results, we just use them in order to print\n",
    "        if len(full_matches)>=n:\n",
    "            mask = list(np.where(np.isin(results, full_matches))[0])\n",
    "\n",
    "        elif len(full_matches)==0:\n",
    "            pass    \n",
    "        # If not, we will include first those with full match and the remaining ones will be ordered\n",
    "        # simply by cosine similarity\n",
    "        else:\n",
    "            full_rank = 0\n",
    "\n",
    "            for i in range(len(results)):\n",
    "                if results[i] in full_matches:\n",
    "                    # Insert the full matches at the beggining to preserve the order of the remaining results\n",
    "                    mask.insert(full_rank, i) \n",
    "                    full_rank+=1\n",
    "\n",
    "        # Ensure we will only print n results\n",
    "        mask = mask[:n]\n",
    "\n",
    "        # Print following the order determined by the mask\n",
    "        for i in mask:\n",
    "            i = int(i)\n",
    "            user_name, text, url, hashtags, favorites, retweets, followers = self._get_tweet_fields(results[i])\n",
    "            if show == True:\n",
    "                print(\"-->\",rank + 1)\n",
    "                print(text,\" | \",user_name,\" | \",self.data.iloc[results[i]]['created_at'],\" | \", hashtags[:] ,\" | \",favorites,\" | \", retweets,\" | \",url, \" | \", followers)\n",
    "            \n",
    "            documents_retrieved.append(results[i])\n",
    "            rank +=1\n",
    "\n",
    "        return documents_retrieved\n",
    "\n",
    "    def query(self, query, n=20, authority=None):\n",
    "        self.return_top_n_doc(query, n, authority)\n",
    "\n",
    "    def interface(self):\n",
    "        while True:\n",
    "            n = int(input(\"Enter the desired number of results: \"))\n",
    "            assert n>0, \"The number of results must be a positive integer number\"\n",
    "            while True:\n",
    "                mode = str(input(\"\"\"Which mode would you like to use (insert number for the desired option)\\n1: TF-IDF\\n2: TF-IDF and authority\\n\"\"\"))\n",
    "                \n",
    "                if mode in MODES:\n",
    "                    break\n",
    "                else:\n",
    "                    print(\"Please insert some of these options: {}\".format(', '.join(MODES)))\n",
    "\n",
    "            query = input(\"Enter your query: \")\n",
    "            if mode == \"1\":\n",
    "                self.query(query, n)\n",
    "            elif mode == \"2\":\n",
    "                self.query(query, n, authority=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwitterSearch_Adapted(TwitterSearch):\n",
    "    def __init__(self,SAMPLE_SIZE):\n",
    "        self.data, self.corpus, self.vectorizer, self.inverted_index = self._load_information_fair(SAMPLE_SIZE)\n",
    "\n",
    "    def _load_information_fair(self,SAMPLE_SIZE): #we introduce a sample size\n",
    "        # Load pretrained vectorizer\n",
    "        vectorizer = pickle.load(open(INPUT_PATH + 'vectorizer.pickle', \"rb\"))\n",
    "\n",
    "        # Load corpus\n",
    "        df = pd.read_csv(INPUT_PATH +'tweets_with_authority.csv')[:SAMPLE_SIZE]\n",
    "        corpus = df['clean_text']\n",
    "        corpus = corpus.fillna('')\n",
    "        corpus = vectorizer.transform(corpus)\n",
    "        \n",
    "        with open(INPUT_PATH + INVERTED_INDEX, 'r') as f:\n",
    "            inverted_index = json.load(f)\n",
    "\n",
    "        return df, corpus, vectorizer, inverted_index\n",
    "    def return_top_n_doc_fair(self,query,n,c_labels = {},show = True,authority = None): #also returns clusters assigned to each doc\n",
    "        \"\"\"\n",
    "        query: Query that the user writes.\n",
    "        tf_idf: dataframe containing tfidf weights for each word in each doc\n",
    "        n: number of doc to return to the user\n",
    "        show: if you want to visualize the results\n",
    "\n",
    "        returns a list with the most top n relevant tweets\n",
    "        \"\"\"\n",
    "        assert n>0, \"n should be a positive integer\"\n",
    "        query = clean_text(query) #noramalize the query\n",
    "        query_vec = self.vectorizer.transform([query]) #calculate tdidf\n",
    "        results = cosine_similarity(self.corpus, query_vec)\n",
    "        results = results.flatten()\n",
    "\n",
    "        documents_retrieved = []\n",
    "\n",
    "        #######Return the results#########\n",
    "        rank=0\n",
    "\n",
    "        if authority is not None:\n",
    "            results = 3*results*0.5*authority\n",
    "\n",
    "        # Reverse the results\n",
    "        results = results.argsort()[::-1]\n",
    "\n",
    "        ## Generate print mask for results\n",
    "\n",
    "        # The mask will contain the indexes from the results array in printing order\n",
    "        # By default this mask will be the first n results of our cosine similarity output\n",
    "        mask = [i for i in range(n)]\n",
    "\n",
    "        # We find those documents that contain all the terms in the query\n",
    "        full_matches = np.array(self.find_full_match_docs(query))\n",
    "\n",
    "        # If we have more full matches than desired results, we just use them in order to print\n",
    "        if len(full_matches)>=n:\n",
    "            mask = list(np.where(np.isin(results, full_matches))[0])\n",
    "\n",
    "        elif len(full_matches)==0:\n",
    "            pass    \n",
    "        # If not, we will include first those with full match and the remaining ones will be ordered\n",
    "        # simply by cosine similarity\n",
    "        else:\n",
    "            full_rank = 0\n",
    "\n",
    "            for i in range(len(results)):\n",
    "                if results[i] in full_matches:\n",
    "                    # Insert the full matches at the beggining to preserve the order of the remaining results\n",
    "                    mask.insert(full_rank, i) \n",
    "                    full_rank+=1\n",
    "\n",
    "        # Ensure we will only print n results\n",
    "        mask = mask[:n]\n",
    "\n",
    "        # Print following the order determined by the mask\n",
    "        #Cluster representation list and rank\n",
    "        clusters_res = []\n",
    "        for i in mask:\n",
    "            i = int(i)\n",
    "            user_name, text, url, hashtags, favorites, retweets, followers = self._get_tweet_fields(results[i])\n",
    "            if show == True:\n",
    "                print(\"-->\",rank + 1)\n",
    "                print(text,\" | \",user_name,\" | \",self.data.iloc[results[i]]['created_at'],\" | \", hashtags[:] ,\" | \",favorites,\" | \", retweets,\" | \",url, \" | \", followers)\n",
    "            \n",
    "            documents_retrieved.append(results[i])\n",
    "            rank +=1\n",
    "            #----OBTAIN CLUSTER INFORMATION----#\n",
    "            if c_labels:\n",
    "                c = c_labels[i]\n",
    "                if show:\n",
    "                    print('Cluster:',c)\n",
    "                    print()\n",
    "\n",
    "                clusters_res.append(c)\n",
    "        return documents_retrieved,clusters_res\n",
    "    \n",
    "    #Compute the similarity to each document in the set returned by the search engine\n",
    "    def compute_sim_doc_set(self,query,docs):\n",
    "        query = clean_text(query)  # Clean the query as the original text\n",
    "        query_vec = self.vectorizer.transform([query])  # calculate its tf-idf score\n",
    "\n",
    "        sim_dict = {}\n",
    "        sim = 0\n",
    "        for i in docs:\n",
    "            sim = cosine_similarity(self.corpus.getrow(i), query_vec)[0][0] # Compute similarity between query and tweets\n",
    "            sim_dict[str(i)] =sim\n",
    "\n",
    "        return sim_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load cluster information from the previous research question RQ1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load clusters obtained in previous question RQ1\n",
    "load_file = INPUT_PATH + 'cluster_labels_docs_4_clusters.npy'\n",
    "c_labels = list(np.load(load_file))\n",
    "c_counts = Counter(c_labels)\n",
    "\n",
    "#Create a label dictionary for each doc\n",
    "l_dict = {}\n",
    "for i,l in enumerate(c_labels):\n",
    "    l_dict[i] = l\n",
    "    \n",
    "#COMPUTE probability of each cluster\n",
    "clusters = np.arange(0,len(c_counts.keys()))\n",
    "c_prob = []\n",
    "for i in clusters:\n",
    "    c_prob.append(c_counts[i]/len(c_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLUSTER PROBABILITIES = P(Vc)\n",
      "Cluster0 -> Prob: 0.301\n",
      "Cluster1 -> Prob: 0.256\n",
      "Cluster2 -> Prob: 0.281\n",
      "Cluster3 -> Prob: 0.163\n"
     ]
    }
   ],
   "source": [
    "print('CLUSTER PROBABILITIES = P(Vc)')\n",
    "for clus, prob in enumerate(c_prob):\n",
    "    print('Cluster{} -> Prob: {}'.format(clus,round(prob,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load tf idf and vectorizer information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = len(c_labels) #Sample Size used\n",
    "se = TwitterSearch_Adapted(SAMPLE_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain STANDARD RESULT of our SEARCH ENGINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> 1\n",
      "Unpopular opinion:\n",
      "\n",
      "If you only have a problem with a COVID vaccine but not with others\n",
      "\n",
      "That's a problem.  |  🇺🇸 𝐏𝐫𝐞𝐬𝐢𝐝𝐞𝐧𝐭-𝐄𝐥𝐞𝐜𝐭 𝐃𝐚𝐯𝐢𝐝 🇺🇸  |  2020-11-19 16:30:59+00:00  |  No hashtags  |  23  |  1  |  No url  |  1649\n",
      "Cluster: 0\n",
      "\n",
      "--> 2\n",
      "@vodaeau @seanhannity COVID Vaccine will cure your mental problem as a bonus too.  |  President Reject Turtleboo  |  2020-11-19 16:30:47+00:00  |  No hashtags  |  1  |  0  |  No url  |  6\n",
      "Cluster: 0\n",
      "\n",
      "--> 3\n",
      "Sure hope that vaccine is optional. Gonna be a huge problem if its not.   |  Max  |  2020-11-19 16:47:24+00:00  |  No hashtags  |  0  |  0  |  https://t.co/zD3vOY2gbm  |  2011\n",
      "Cluster: 1\n",
      "\n",
      "--> 4\n",
      "@MyBeardAndBooks @Pastor_Gabe No. Getting Covid could cause death. Getting the vaccine couldn't. Therefore getting the vaccine is less dangerous (less deadly) than getting the disease. Getting Covid can also cause long term health problems that the vaccine doesn't cause, so again vaccine less dangerous.  |  Meg’s ready for Christmas -‘tis the season🇬🇧🇺🇸  |  2020-11-19 15:43:27+00:00  |  No hashtags  |  7  |  0  |  No url  |  183\n",
      "Cluster: 2\n",
      "\n",
      "--> 5\n",
      "The real problem will be when corporate pushes vaccines... No entry into our store without proof of vaccine....\n",
      "We'll all have to run around with red \"V's\" on it foreheads just to find out the site is still out of TP.   |  Citizen-Elect Matt  |  2020-11-19 16:27:21+00:00  |  No hashtags  |  1  |  0  |  https://t.co/13QotLptcu  |  59\n",
      "Cluster: 1\n",
      "\n",
      "--> 6\n",
      "People getting mad they might have to prove they’ve been COVID vaccinated to attend certain events... like I among thousands if not millions of other students had to get a meningitis vaccination before staying in college dorms??? what’s the problem now... pack it up tin foil hats  |  robérto  |  2020-11-19 16:55:14+00:00  |  No hashtags  |  76  |  18  |  No url  |  2475\n",
      "Cluster: 1\n",
      "\n",
      "--> 7\n",
      "Flu has been thrown out of consideration of a virus problem, with vaccines that “cure” 50% +/- of the influenza virus, not 90 or 95% as COVID can!  CDC WILL NOT TRACK INFLUENZA THIS YEAR EITHER, 🤔🤔🥱🥱 because it is GONE!☠️☠️ Geez we believe this? 90 &amp; 95% vaccine in 6 months?   |  Chuck Baldwin  |  2020-11-19 15:42:52+00:00  |  No hashtags  |  5  |  1  |  https://t.co/l0BnXCLKV7  |  719\n",
      "Cluster: 3\n",
      "\n",
      "--> 8\n",
      "@joshmartin98 Come on Josh. You know we are testing the way we are for COVID because there isn’t a vaccine or known treatment yet. Financial incentives driving questionable decisions by hospitals is nothing new, it’s capitalism at its finest.  Just a few more months, we’ll be over this problem  |  Coach Jason  |  2020-11-19 15:41:15+00:00  |  No hashtags  |  0  |  0  |  No url  |  194\n",
      "Cluster: 3\n",
      "\n",
      "--> 9\n",
      "@cher Stop the BS... blaming someone for covid is BS... USA has more doctors, labs, money spent on vaccine than any other country and will be 1st country to have 1... this is a GLOBAL problem not a presidential, stop being ignorant  |  LadyGia5919  |  2020-11-19 16:00:17+00:00  |  No hashtags  |  0  |  0  |  No url  |  10\n",
      "Cluster: 1\n",
      "\n",
      "--> 10\n",
      "@BerezinoS I get a flu shot every year. I had the flu one time and was very ill. I don't want to ever go through that again! The problem with Covid is we don't know how our body is going to react to it. I live with my older parents so if the vaccine is safe I'll get it to protect all of us.  |  Melanie, but just call me Mel😁❤  |  2020-11-19 16:35:11+00:00  |  No hashtags  |  0  |  0  |  No url  |  1575\n",
      "Cluster: 2\n",
      "\n",
      "--> 11\n",
      "@charliekirk11 @charziard6 Lockdown is a short-term solution for Covid, and the risks scientists are mentioning are other ways people are becoming sickly, such as fewer immunizations or cardiovascular problems. News of vaccination is great for the herd immunity concept.  |  Ms.Queenbee87  |  2020-11-19 16:07:03+00:00  |  No hashtags  |  0  |  0  |  No url  |  512\n",
      "Cluster: 0\n",
      "\n",
      "--> 12\n",
      "I made a vaccine that stops Covid in it's tracks100%, is taken orally and has no side effects\n",
      "It will also increase your sex drive by 100% and raises your IQ by 25 points\n",
      "The only problem is it has to be stored at absolute zero  |  George Carlin's Comedy Vault  |  2020-11-19 16:11:51+00:00  |  No hashtags  |  11  |  1  |  No url  |  50393\n",
      "Cluster: 3\n",
      "\n",
      "--> 13\n",
      "@realDonaldTrump How can anyone believe what this president says.  He has been proven a liar time and time and time.......on and on. He can't take credit for the vaccines.  He doesn't even believe Covid is a problem unless it suits his agenda. Can't wait until Jan 20/21  |  Evelyn  |  2020-11-19 16:51:45+00:00  |  No hashtags  |  0  |  0  |  No url  |  4\n",
      "Cluster: 2\n",
      "\n",
      "--> 14\n",
      "@OANN @99Cindygrice What? The other 5% transform into genetic monopolies &amp; die a horrible death? That'd be pretty norm for pfizer, actually.\n",
      "\n",
      "But, if vaccine is forced, 70 million ppl get it...that's 3.5 MILLION ppl it has no covid effect but other problems?\n",
      "\n",
      "We're statistically safer with COVID.🤪  |  DK  |  2020-11-19 16:42:43+00:00  |  No hashtags  |  0  |  0  |  No url  |  64\n",
      "Cluster: 0\n",
      "\n",
      "--> 15\n",
      "@GovMikeDeWine We don't have a COVID problem.\n",
      "We have a tyranny problem.  |  Food For Thought  |  2020-11-19 15:46:24+00:00  |  No hashtags  |  6  |  0  |  No url  |  3808\n",
      "Cluster: 3\n",
      "\n",
      "--> 16\n",
      "@GovMikeDeWine We don't have a COVID problem.\n",
      "We have a tyranny problem.  |  Food For Thought  |  2020-11-19 15:45:54+00:00  |  No hashtags  |  3  |  0  |  No url  |  3808\n",
      "Cluster: 0\n",
      "\n",
      "--> 17\n",
      "Unpopular opinion:\n",
      "\n",
      "If you only have a problem with a COVID vaccine but not with others\n",
      "\n",
      "That's a problem.  |  🇺🇸 𝐏𝐫𝐞𝐬𝐢𝐝𝐞𝐧𝐭-𝐄𝐥𝐞𝐜𝐭 𝐃𝐚𝐯𝐢𝐝 🇺🇸  |  2020-11-19 16:30:59+00:00  |  No hashtags  |  23  |  1  |  No url  |  1649\n",
      "Cluster: 0\n",
      "\n",
      "--> 18\n",
      "@OregonGovBrown You dumb bitch! Mitch is not the problem. Covid is not the problem. Evil ass ppl like you are the problem.  |  Josh  |  2020-11-19 16:29:24+00:00  |  No hashtags  |  0  |  0  |  No url  |  4\n",
      "Cluster: 2\n",
      "\n",
      "--> 19\n",
      "NO vaccine for you!   |  Silent_Saber  |  2020-11-19 16:46:07+00:00  |  No hashtags  |  0  |  0  |  https://t.co/wssjp57jsa  |  63\n",
      "Cluster: 3\n",
      "\n",
      "--> 20\n",
      "Not because of a vaccine!   |  Super Elite Deplorable Wanda  |  2020-11-19 16:13:53+00:00  |  No hashtags  |  0  |  0  |  https://t.co/gXEMSfzW0a  |  514\n",
      "Cluster: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#query='Covid deaths England November'\n",
    "query='Problems with the vaccine'\n",
    "TOP = 20\n",
    "doc,clusters_std_res = se.return_top_n_doc_fair(query,TOP,c_labels=l_dict,show=True, authority=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_dict = se.compute_sim_doc_set(query,doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RE-RANKING ALGORITHM TAKING INTO ACCOUNT FAIRNESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FAIRNESS_Re_Ranking(TwitterSearch_Adapted):\n",
    "    def __init__(self, doc_set,sim_dict, c_prob, c_labels,lambda_value, Fair_rank_size,SAMPLE_SIZE):\n",
    "            self.doc_set = doc_set\n",
    "            self.sim_dict = sim_dict\n",
    "            self.l_dict = c_labels\n",
    "            self.Rank_size = Fair_rank_size\n",
    "            self.c_prob = c_prob\n",
    "            self.lambda_value = lambda_value\n",
    "            self.fair_set = []\n",
    "            self.clusters_res = []\n",
    "            self.SAMPLE_SIZE = SAMPLE_SIZE\n",
    "    def fairness_in_res(self,doc_cluster):\n",
    "        #if a cluster is already in the set this wil be 0\n",
    "\n",
    "        fair_set_clusters = [self.l_dict[doc] for doc in self.fair_set] #calculate the clusters represented in the fair set\n",
    "        cluster_representation = Counter(fair_set_clusters)\n",
    "        # If a cluster not represented return 1, else return 0\n",
    "        if len(self.fair_set) < len(set(self.l_dict.items())): #While not all clusters represented use the algorithm proposed\n",
    "            if doc_cluster in fair_set_clusters:\n",
    "                return 0\n",
    "            else:\n",
    "                return 1\n",
    "        else:\n",
    "            percentage_cluster = cluster_representation[doc_cluster]/len(self.fair_set)\n",
    "\n",
    "            return (1 - percentage_cluster)\n",
    "        '''\n",
    "        if doc_cluster in fair_set_clusters:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "        '''\n",
    "    def fairness_score(self, doc_index):\n",
    "        #Compute the fairness for the cluster where the document belongs\n",
    "        #We are assuming that a document can only belong to one cluster\n",
    "        document_cluster = self.l_dict[doc_index]\n",
    "        f_score = self.c_prob[document_cluster] * self.fairness_in_res(document_cluster)\n",
    "        return f_score\n",
    "    def compute_diversity_score(self):\n",
    "        '''\n",
    "        INPUTS:\n",
    "        doc_set = R(u)\n",
    "        sim_dict : Equivalent to results matrix obtained in return_top_n_doc P(v|u)\n",
    "        cluster_prob: Prior probabilities of each cluster. P(Vc)\n",
    "        lam = value for the lambda\n",
    "        '''\n",
    "        div_score = [] #List of diversity scores for each document in the R(u) set\n",
    "        f_score = 0\n",
    "        for doc_index in self.doc_set:\n",
    "            similarity_measure = (1-self.lambda_value) * self.sim_dict[str(doc_index)] #P(v|u) = similarity (in our case definition)\n",
    "            f_score = self.lambda_value * self.fairness_score(doc_index)\n",
    "            div_score.append(similarity_measure + f_score)\n",
    "        print(div_score)\n",
    "        doc_more_fair = np.argmax(div_score)\n",
    "        print(doc_more_fair)\n",
    "        return self.doc_set[doc_more_fair], div_score\n",
    "    \n",
    "    def print_results(self,print_labels = True,show = True):\n",
    "        #print the documents contained in docs\n",
    "        if show:\n",
    "            self.data, self.corpus, self.vectorizer, self.inverted_index = self._load_information_fair(SAMPLE_SIZE)\n",
    "        for rank, doc in enumerate(self.fair_set):\n",
    "            if show:\n",
    "                user_name, text, url, hashtags, favorites, retweets, followers = self._get_tweet_fields(doc)\n",
    "                print(\"{} -- User: {} ({} followers) | RT: {} | FAV: {}\".format(rank+1, user_name, followers, retweets, favorites))\n",
    "                print(\"-------------------------\")\n",
    "                print(\"text:\",text)\n",
    "                print(\"-------------------------\")\n",
    "            if print_labels:\n",
    "                c = self.l_dict[doc]\n",
    "                if show:\n",
    "                    print('Cluster:',c)\n",
    "                    print()\n",
    "                self.clusters_res.append(c)\n",
    "            rank +=1\n",
    "    \n",
    "    def Re_Ranking_Fairness(self, print_labels = True,show=True):\n",
    "        #initialized R(u) = doc_set, and S(u)= fari_set\n",
    "        #RUN RE RANK ALGORITHM\n",
    "        for i in range(0,self.Rank_size):\n",
    "            doc_more_fair, div_score = self.compute_diversity_score()\n",
    "            self.fair_set.append(doc_more_fair)\n",
    "            self.doc_set.remove(doc_more_fair)\n",
    "            \n",
    "        self.print_results(print_labels,show)\n",
    "        #return fair_set,cluster_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[36902,\n",
       " 36745,\n",
       " 48625,\n",
       " 4243,\n",
       " 34212,\n",
       " 54442,\n",
       " 3858,\n",
       " 2771,\n",
       " 15523,\n",
       " 39869,\n",
       " 20507,\n",
       " 23841,\n",
       " 51879,\n",
       " 45139,\n",
       " 6232,\n",
       " 5897,\n",
       " 36902,\n",
       " 35597,\n",
       " 47672,\n",
       " 25213]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'36902': 0.6271392864879529,\n",
       " '36745': 0.47845024075906417,\n",
       " '48625': 0.4572082052844404,\n",
       " '4243': 0.3377881558513894,\n",
       " '34212': 0.3103699717442669,\n",
       " '54442': 0.2589014036959796,\n",
       " '3858': 0.24503952203035242,\n",
       " '2771': 0.2388063975128234,\n",
       " '15523': 0.2311242390337217,\n",
       " '39869': 0.22971112148343525,\n",
       " '20507': 0.22444582519569567,\n",
       " '23841': 0.22310171592739736,\n",
       " '51879': 0.21838678081410512,\n",
       " '45139': 0.18656254902643166,\n",
       " '6232': 0.6499118133908676,\n",
       " '5897': 0.6499118133908676,\n",
       " '35597': 0.5837953492386018,\n",
       " '47672': 0.5686604905084611,\n",
       " '25213': 0.5686604905084611}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6271392864879529, 0.47845024075906417, 0.4572082052844404, 0.3377881558513894, 0.3103699717442669, 0.2589014036959796, 0.24503952203035242, 0.2388063975128234, 0.2311242390337217, 0.22971112148343525, 0.22444582519569567, 0.22310171592739736, 0.21838678081410512, 0.18656254902643166, 0.6499118133908676, 0.6499118133908676, 0.6271392864879529, 0.5837953492386018, 0.5686604905084611, 0.5686604905084611]\n",
      "14\n",
      "[0.6271392864879529, 0.47845024075906417, 0.4572082052844404, 0.3377881558513894, 0.3103699717442669, 0.2589014036959796, 0.24503952203035242, 0.2388063975128234, 0.2311242390337217, 0.22971112148343525, 0.22444582519569567, 0.22310171592739736, 0.21838678081410512, 0.18656254902643166, 0.6499118133908676, 0.6271392864879529, 0.5837953492386018, 0.5686604905084611, 0.5686604905084611]\n",
      "14\n",
      "[0.6271392864879529, 0.47845024075906417, 0.4572082052844404, 0.3377881558513894, 0.3103699717442669, 0.2589014036959796, 0.24503952203035242, 0.2388063975128234, 0.2311242390337217, 0.22971112148343525, 0.22444582519569567, 0.22310171592739736, 0.21838678081410512, 0.18656254902643166, 0.6271392864879529, 0.5837953492386018, 0.5686604905084611, 0.5686604905084611]\n",
      "0\n",
      "[0.47845024075906417, 0.4572082052844404, 0.3377881558513894, 0.3103699717442669, 0.2589014036959796, 0.24503952203035242, 0.2388063975128234, 0.2311242390337217, 0.22971112148343525, 0.22444582519569567, 0.22310171592739736, 0.21838678081410512, 0.18656254902643166, 0.6271392864879529, 0.5837953492386018, 0.5686604905084611, 0.5686604905084611]\n",
      "13\n",
      "[0.47845024075906417, 0.4572082052844404, 0.3377881558513894, 0.3103699717442669, 0.2589014036959796, 0.24503952203035242, 0.2388063975128234, 0.2311242390337217, 0.22971112148343525, 0.22444582519569567, 0.22310171592739736, 0.21838678081410512, 0.18656254902643166, 0.5837953492386018, 0.5686604905084611, 0.5686604905084611]\n",
      "13\n",
      "[0.47845024075906417, 0.4572082052844404, 0.3377881558513894, 0.3103699717442669, 0.2589014036959796, 0.24503952203035242, 0.2388063975128234, 0.2311242390337217, 0.22971112148343525, 0.22444582519569567, 0.22310171592739736, 0.21838678081410512, 0.18656254902643166, 0.5686604905084611, 0.5686604905084611]\n",
      "13\n",
      "[0.47845024075906417, 0.4572082052844404, 0.3377881558513894, 0.3103699717442669, 0.2589014036959796, 0.24503952203035242, 0.2388063975128234, 0.2311242390337217, 0.22971112148343525, 0.22444582519569567, 0.22310171592739736, 0.21838678081410512, 0.18656254902643166, 0.5686604905084611]\n",
      "13\n",
      "[0.47845024075906417, 0.4572082052844404, 0.3377881558513894, 0.3103699717442669, 0.2589014036959796, 0.24503952203035242, 0.2388063975128234, 0.2311242390337217, 0.22971112148343525, 0.22444582519569567, 0.22310171592739736, 0.21838678081410512, 0.18656254902643166]\n",
      "0\n",
      "[0.4572082052844404, 0.3377881558513894, 0.3103699717442669, 0.2589014036959796, 0.24503952203035242, 0.2388063975128234, 0.2311242390337217, 0.22971112148343525, 0.22444582519569567, 0.22310171592739736, 0.21838678081410512, 0.18656254902643166]\n",
      "0\n",
      "[0.3377881558513894, 0.3103699717442669, 0.2589014036959796, 0.24503952203035242, 0.2388063975128234, 0.2311242390337217, 0.22971112148343525, 0.22444582519569567, 0.22310171592739736, 0.21838678081410512, 0.18656254902643166]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "doc_set = doc.copy()\n",
    "lambda_val = 0\n",
    "Rank_size = 10\n",
    "FAIR_RANK = FAIRNESS_Re_Ranking(doc_set,sim_dict,c_prob,l_dict,lambda_val,Rank_size,SAMPLE_SIZE)\n",
    "FAIR_RANK.Re_Ranking_Fairness(show=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clutsers obtained in the two results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_clusters_in_result(doc,clusters_std_res,top = None,title = 'STANDARD SEARCH ENGINE'):\n",
    "    if top:\n",
    "        doc = doc[:top]\n",
    "        clusters_std_res = clusters_std_res[:top]\n",
    "    print('Cluster Representation in ' + title)\n",
    "    print(Counter(clusters_std_res))\n",
    "    print()\n",
    "    rank = 0\n",
    "    for d,clust in zip(doc,clusters_std_res):\n",
    "        print('{} >> Document {}, C {}'.format(rank+1,d,clust))\n",
    "        rank += 1\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Representation in STANDARD SEARCH ENGINE\n",
      "Counter({1: 4, 0: 2, 2: 2, 3: 2})\n",
      "\n",
      "1 >> Document 36902, C 0\n",
      "2 >> Document 36745, C 0\n",
      "3 >> Document 48625, C 1\n",
      "4 >> Document 4243, C 2\n",
      "5 >> Document 34212, C 1\n",
      "6 >> Document 54442, C 1\n",
      "7 >> Document 3858, C 3\n",
      "8 >> Document 2771, C 3\n",
      "9 >> Document 15523, C 1\n",
      "10 >> Document 39869, C 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_clusters_in_result(doc,clusters_std_res,top =FAIR_RANK.Rank_size,title = 'STANDARD SEARCH ENGINE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Representation in FAIR RES\n",
      "Counter({0: 4, 2: 4, 1: 1, 3: 1})\n",
      "\n",
      "1 >> Document 36902, C 0\n",
      "2 >> Document 6232, C 2\n",
      "3 >> Document 4243, C 1\n",
      "4 >> Document 39869, C 3\n",
      "5 >> Document 5897, C 2\n",
      "6 >> Document 36902, C 0\n",
      "7 >> Document 35597, C 2\n",
      "8 >> Document 47672, C 0\n",
      "9 >> Document 25213, C 2\n",
      "10 >> Document 36745, C 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_clusters_in_result(FAIR_RANK.fair_set,FAIR_RANK.clusters_res,top = None,title = 'FAIR RES')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COMPUTING CORRELATION BETWEEN RANKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SPEARMANS CORRELATION: Intuitively, the Spearman correlation between two variables will be high when observations have a similar (or identical for a correlation of 1) rank (i.e. relative position label of the observations within the variable: 1st, 2nd, 3rd, etc.) between the two variables, and low when observations have a dissimilar (or fully opposed for a correlation of −1) rank between the two variables.\n",
    "\n",
    "KENDALL CORRELATION: Intuitively, the Kendall correlation between two variables will be high when observations have a similar (or identical for a correlation of 1) rank (i.e. relative position label of the observations within the variable: 1st, 2nd, 3rd, etc.) between the two variables, and low when observations have a dissimilar (or fully different for a correlation of −1) rank between the two variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "query_list = ['Why does trump not wear a mask?',\n",
    "              'News from covid',\n",
    "              'When will the covid vaccine be available?',\n",
    "              'How many people has died from covid?',\n",
    "              'Covid deaths england November',\n",
    "              'Covid total number of tests',\n",
    "              'What does trump say about covid?',\n",
    "              'Covid impact Amazon company',\n",
    "              'Covid vaccine trials',\n",
    "              'Covid death rate'\n",
    "              ]\n",
    "#### -------HYPERPARAMETER SET------------------\n",
    "SEARCH_SPACE = 20\n",
    "TOP  = 10\n",
    "Fair_Rank_size = 10\n",
    "lambda_value = 0\n",
    "SAMPLE_SIZE = len(c_labels) #Sample Size used\n",
    "\n",
    "se = TwitterSearch_Adapted(SAMPLE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query >>  Why does trump not wear a mask?\n",
      "Cluster Representation in STANDARD SEARCH ENGINE\n",
      "Counter({1: 4, 0: 2, 2: 2, 3: 2})\n",
      "\n",
      "1 >> Document 20321, C 0\n",
      "2 >> Document 1361, C 2\n",
      "3 >> Document 26351, C 0\n",
      "4 >> Document 8639, C 1\n",
      "5 >> Document 33784, C 3\n",
      "6 >> Document 27478, C 2\n",
      "7 >> Document 160, C 3\n",
      "8 >> Document 46591, C 1\n",
      "9 >> Document 30887, C 1\n",
      "10 >> Document 41103, C 1\n",
      "\n",
      "Cluster Representation in FAIR SEARCH ENGINE\n",
      "Counter({2: 4, 1: 4, 0: 2})\n",
      "\n",
      "1 >> Document 20321, C 2\n",
      "2 >> Document 1361, C 1\n",
      "3 >> Document 26351, C 2\n",
      "4 >> Document 8639, C 0\n",
      "5 >> Document 33784, C 1\n",
      "6 >> Document 27478, C 1\n",
      "7 >> Document 160, C 1\n",
      "8 >> Document 46591, C 0\n",
      "9 >> Document 30887, C 2\n",
      "10 >> Document 41103, C 2\n",
      "\n",
      "----RANKS OBTAINED------\n",
      "Not Fair:  [11010, 12203, 42470, 41499, 18951, 42314, 32964, 31013, 52266, 49386]\n",
      "Fair:      [20321, 1361, 26351, 8639, 33784, 27478, 160, 46591, 30887, 41103]\n",
      "Spearmans Rank Correlation 0.31 and p_value 0.38.\n",
      "Kendalls Rank Correlation 0.24 and p_value 0.38.\n",
      "\n",
      "Query >>  News from covid\n",
      "Cluster Representation in STANDARD SEARCH ENGINE\n",
      "Counter({3: 4, 0: 3, 2: 2, 1: 1})\n",
      "\n",
      "1 >> Document 54298, C 0\n",
      "2 >> Document 54321, C 0\n",
      "3 >> Document 12339, C 3\n",
      "4 >> Document 50303, C 2\n",
      "5 >> Document 51576, C 0\n",
      "6 >> Document 53145, C 3\n",
      "7 >> Document 44406, C 1\n",
      "8 >> Document 30878, C 3\n",
      "9 >> Document 45943, C 3\n",
      "10 >> Document 25189, C 2\n",
      "\n",
      "Cluster Representation in FAIR SEARCH ENGINE\n",
      "Counter({0: 3, 1: 3, 2: 3, 3: 1})\n",
      "\n",
      "1 >> Document 54298, C 0\n",
      "2 >> Document 54321, C 1\n",
      "3 >> Document 12339, C 2\n",
      "4 >> Document 50303, C 2\n",
      "5 >> Document 51576, C 0\n",
      "6 >> Document 53145, C 1\n",
      "7 >> Document 44406, C 0\n",
      "8 >> Document 30878, C 2\n",
      "9 >> Document 45943, C 1\n",
      "10 >> Document 25189, C 3\n",
      "\n",
      "----RANKS OBTAINED------\n",
      "Not Fair:  [49781, 9463, 40335, 24698, 29320, 9296, 38533, 31878, 6932, 24220]\n",
      "Fair:      [54298, 54321, 12339, 50303, 51576, 53145, 44406, 30878, 45943, 25189]\n",
      "Spearmans Rank Correlation -0.24 and p_value 0.51.\n",
      "Kendalls Rank Correlation -0.16 and p_value 0.6.\n",
      "\n",
      "Query >>  When will the covid vaccine be available?\n",
      "Cluster Representation in STANDARD SEARCH ENGINE\n",
      "Counter({0: 4, 3: 3, 2: 3})\n",
      "\n",
      "1 >> Document 8275, C 3\n",
      "2 >> Document 35653, C 0\n",
      "3 >> Document 2243, C 0\n",
      "4 >> Document 51635, C 2\n",
      "5 >> Document 5214, C 0\n",
      "6 >> Document 27079, C 0\n",
      "7 >> Document 11010, C 2\n",
      "8 >> Document 42881, C 3\n",
      "9 >> Document 20136, C 3\n",
      "10 >> Document 49657, C 2\n",
      "\n",
      "Cluster Representation in FAIR SEARCH ENGINE\n",
      "Counter({0: 3, 3: 3, 1: 2, 2: 2})\n",
      "\n",
      "1 >> Document 8275, C 1\n",
      "2 >> Document 35653, C 0\n",
      "3 >> Document 2243, C 2\n",
      "4 >> Document 51635, C 0\n",
      "5 >> Document 5214, C 1\n",
      "6 >> Document 27079, C 3\n",
      "7 >> Document 11010, C 0\n",
      "8 >> Document 42881, C 3\n",
      "9 >> Document 20136, C 3\n",
      "10 >> Document 49657, C 2\n",
      "\n",
      "----RANKS OBTAINED------\n",
      "Not Fair:  [23940, 24994, 40443, 23916, 1606, 23717, 9959, 42336, 31284, 41041]\n",
      "Fair:      [8275, 35653, 2243, 51635, 5214, 27079, 11010, 42881, 20136, 49657]\n",
      "Spearmans Rank Correlation 0.32 and p_value 0.37.\n",
      "Kendalls Rank Correlation 0.24 and p_value 0.38.\n",
      "\n",
      "Query >>  How many people has died from covid?\n",
      "Cluster Representation in STANDARD SEARCH ENGINE\n",
      "Counter({1: 4, 0: 2, 2: 2, 3: 2})\n",
      "\n",
      "1 >> Document 7079, C 0\n",
      "2 >> Document 27632, C 2\n",
      "3 >> Document 40735, C 0\n",
      "4 >> Document 35734, C 1\n",
      "5 >> Document 40922, C 2\n",
      "6 >> Document 37273, C 3\n",
      "7 >> Document 47065, C 1\n",
      "8 >> Document 41025, C 1\n",
      "9 >> Document 50861, C 1\n",
      "10 >> Document 9553, C 3\n",
      "\n",
      "Cluster Representation in FAIR SEARCH ENGINE\n",
      "Counter({0: 3, 1: 3, 2: 3, 3: 1})\n",
      "\n",
      "1 >> Document 7079, C 0\n",
      "2 >> Document 27632, C 1\n",
      "3 >> Document 40735, C 2\n",
      "4 >> Document 35734, C 0\n",
      "5 >> Document 40922, C 0\n",
      "6 >> Document 37273, C 1\n",
      "7 >> Document 47065, C 2\n",
      "8 >> Document 41025, C 2\n",
      "9 >> Document 50861, C 1\n",
      "10 >> Document 9553, C 3\n",
      "\n",
      "----RANKS OBTAINED------\n",
      "Not Fair:  [17906, 52797, 26465, 48601, 50699, 49806, 28581, 31157, 12138, 45494]\n",
      "Fair:      [7079, 27632, 40735, 35734, 40922, 37273, 47065, 41025, 50861, 9553]\n",
      "Spearmans Rank Correlation -0.28 and p_value 0.43.\n",
      "Kendalls Rank Correlation -0.2 and p_value 0.48.\n",
      "\n",
      "Query >>  Covid deaths england November\n",
      "Cluster Representation in STANDARD SEARCH ENGINE\n",
      "Counter({0: 4, 2: 4, 3: 2})\n",
      "\n",
      "1 >> Document 42479, C 3\n",
      "2 >> Document 6962, C 0\n",
      "3 >> Document 27981, C 0\n",
      "4 >> Document 40426, C 2\n",
      "5 >> Document 39186, C 3\n",
      "6 >> Document 27739, C 0\n",
      "7 >> Document 48440, C 2\n",
      "8 >> Document 20039, C 0\n",
      "9 >> Document 35566, C 2\n",
      "10 >> Document 50388, C 2\n",
      "\n",
      "Cluster Representation in FAIR SEARCH ENGINE\n",
      "Counter({2: 5, 1: 3, 3: 1, 0: 1})\n",
      "\n",
      "1 >> Document 42479, C 2\n",
      "2 >> Document 6962, C 2\n",
      "3 >> Document 27981, C 2\n",
      "4 >> Document 40426, C 2\n",
      "5 >> Document 39186, C 1\n",
      "6 >> Document 27739, C 1\n",
      "7 >> Document 48440, C 3\n",
      "8 >> Document 20039, C 2\n",
      "9 >> Document 35566, C 1\n",
      "10 >> Document 50388, C 0\n",
      "\n",
      "----RANKS OBTAINED------\n",
      "Not Fair:  [1035, 9047, 45200, 20323, 49438, 38042, 18922, 51128, 17401, 32368]\n",
      "Fair:      [42479, 6962, 27981, 40426, 39186, 27739, 48440, 20039, 35566, 50388]\n",
      "Spearmans Rank Correlation -0.24 and p_value 0.51.\n",
      "Kendalls Rank Correlation -0.16 and p_value 0.6.\n",
      "\n",
      "Query >>  Covid total number of tests\n",
      "Cluster Representation in STANDARD SEARCH ENGINE\n",
      "Counter({2: 4, 0: 4, 3: 2})\n",
      "\n",
      "1 >> Document 1699, C 2\n",
      "2 >> Document 28712, C 3\n",
      "3 >> Document 5600, C 0\n",
      "4 >> Document 12180, C 0\n",
      "5 >> Document 42748, C 2\n",
      "6 >> Document 11074, C 3\n",
      "7 >> Document 33046, C 0\n",
      "8 >> Document 31764, C 2\n",
      "9 >> Document 34579, C 0\n",
      "10 >> Document 43008, C 2\n",
      "\n",
      "Cluster Representation in FAIR SEARCH ENGINE\n",
      "Counter({2: 5, 3: 2, 1: 2, 0: 1})\n",
      "\n",
      "1 >> Document 28712, C 2\n",
      "2 >> Document 5600, C 3\n",
      "3 >> Document 12180, C 2\n",
      "4 >> Document 42748, C 1\n",
      "5 >> Document 11074, C 3\n",
      "6 >> Document 33046, C 2\n",
      "7 >> Document 31764, C 1\n",
      "8 >> Document 34579, C 2\n",
      "9 >> Document 43008, C 2\n",
      "10 >> Document 36004, C 0\n",
      "\n",
      "----RANKS OBTAINED------\n",
      "Not Fair:  [1699, 23438, 36877, 54175, 29581, 5999, 12640, 28759, 23815, 48799]\n",
      "Fair:      [28712, 5600, 12180, 42748, 11074, 33046, 31764, 34579, 43008, 36004]\n",
      "Spearmans Rank Correlation 0.3 and p_value 0.4.\n",
      "Kendalls Rank Correlation 0.24 and p_value 0.38.\n",
      "\n",
      "Query >>  What does trump say about covid?\n",
      "Cluster Representation in STANDARD SEARCH ENGINE\n",
      "Counter({2: 4, 3: 3, 0: 2, 1: 1})\n",
      "\n",
      "1 >> Document 15259, C 3\n",
      "2 >> Document 37976, C 2\n",
      "3 >> Document 36943, C 2\n",
      "4 >> Document 34822, C 3\n",
      "5 >> Document 34467, C 1\n",
      "6 >> Document 34405, C 3\n",
      "7 >> Document 35894, C 0\n",
      "8 >> Document 34758, C 2\n",
      "9 >> Document 34897, C 0\n",
      "10 >> Document 35824, C 2\n",
      "\n",
      "Cluster Representation in FAIR SEARCH ENGINE\n",
      "Counter({0: 6, 1: 3, 3: 1})\n",
      "\n",
      "1 >> Document 15259, C 0\n",
      "2 >> Document 37976, C 1\n",
      "3 >> Document 36943, C 1\n",
      "4 >> Document 34822, C 0\n",
      "5 >> Document 34467, C 0\n",
      "6 >> Document 34405, C 0\n",
      "7 >> Document 35894, C 3\n",
      "8 >> Document 34758, C 1\n",
      "9 >> Document 34897, C 0\n",
      "10 >> Document 35824, C 0\n",
      "\n",
      "----RANKS OBTAINED------\n",
      "Not Fair:  [34225, 35755, 36727, 36829, 37889, 4516, 3771, 52910, 27826, 17927]\n",
      "Fair:      [15259, 37976, 36943, 34822, 34467, 34405, 35894, 34758, 34897, 35824]\n",
      "Spearmans Rank Correlation -0.13 and p_value 0.73.\n",
      "Kendalls Rank Correlation -0.16 and p_value 0.6.\n",
      "\n",
      "Query >>  Covid impact Amazon company\n",
      "Cluster Representation in STANDARD SEARCH ENGINE\n",
      "Counter({0: 4, 2: 4, 3: 2})\n",
      "\n",
      "1 >> Document 6208, C 3\n",
      "2 >> Document 53429, C 0\n",
      "3 >> Document 53290, C 0\n",
      "4 >> Document 53015, C 2\n",
      "5 >> Document 3876, C 3\n",
      "6 >> Document 16283, C 0\n",
      "7 >> Document 1402, C 2\n",
      "8 >> Document 41960, C 0\n",
      "9 >> Document 6787, C 2\n",
      "10 >> Document 9743, C 2\n",
      "\n",
      "Cluster Representation in FAIR SEARCH ENGINE\n",
      "Counter({1: 3, 2: 3, 3: 3, 0: 1})\n",
      "\n",
      "1 >> Document 6208, C 1\n",
      "2 >> Document 53429, C 2\n",
      "3 >> Document 53290, C 3\n",
      "4 >> Document 53015, C 0\n",
      "5 >> Document 3876, C 3\n",
      "6 >> Document 16283, C 1\n",
      "7 >> Document 1402, C 2\n",
      "8 >> Document 41960, C 3\n",
      "9 >> Document 6787, C 2\n",
      "10 >> Document 9743, C 1\n",
      "\n",
      "----RANKS OBTAINED------\n",
      "Not Fair:  [40162, 49554, 11062, 5017, 52468, 32993, 34208, 24894, 0, 11279]\n",
      "Fair:      [6208, 53429, 53290, 53015, 3876, 16283, 1402, 41960, 6787, 9743]\n",
      "Spearmans Rank Correlation -0.28 and p_value 0.43.\n",
      "Kendalls Rank Correlation -0.2 and p_value 0.48.\n",
      "\n",
      "Query >>  Covid vaccine trials\n",
      "Cluster Representation in STANDARD SEARCH ENGINE\n",
      "Counter({2: 5, 3: 3, 0: 2})\n",
      "\n",
      "1 >> Document 12091, C 2\n",
      "2 >> Document 31813, C 2\n",
      "3 >> Document 8295, C 0\n",
      "4 >> Document 18581, C 3\n",
      "5 >> Document 18097, C 0\n",
      "6 >> Document 36533, C 2\n",
      "7 >> Document 11768, C 2\n",
      "8 >> Document 27382, C 3\n",
      "9 >> Document 33510, C 2\n",
      "10 >> Document 34161, C 3\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Representation in FAIR SEARCH ENGINE\n",
      "Counter({2: 5, 1: 2, 3: 2, 0: 1})\n",
      "\n",
      "1 >> Document 12091, C 1\n",
      "2 >> Document 31813, C 2\n",
      "3 >> Document 8295, C 1\n",
      "4 >> Document 18581, C 3\n",
      "5 >> Document 18097, C 3\n",
      "6 >> Document 36533, C 2\n",
      "7 >> Document 11768, C 2\n",
      "8 >> Document 27382, C 0\n",
      "9 >> Document 33510, C 2\n",
      "10 >> Document 34161, C 2\n",
      "\n",
      "----RANKS OBTAINED------\n",
      "Not Fair:  [8201, 39074, 15464, 29456, 5021, 35935, 29036, 47323, 857, 10025]\n",
      "Fair:      [12091, 31813, 8295, 18581, 18097, 36533, 11768, 27382, 33510, 34161]\n",
      "Spearmans Rank Correlation 0.16 and p_value 0.65.\n",
      "Kendalls Rank Correlation 0.11 and p_value 0.73.\n",
      "\n",
      "Query >>  Covid death rate\n",
      "Cluster Representation in STANDARD SEARCH ENGINE\n",
      "Counter({3: 3, 2: 3, 0: 2, 1: 2})\n",
      "\n",
      "1 >> Document 51128, C 3\n",
      "2 >> Document 48813, C 0\n",
      "3 >> Document 903, C 2\n",
      "4 >> Document 25038, C 3\n",
      "5 >> Document 54941, C 2\n",
      "6 >> Document 17968, C 1\n",
      "7 >> Document 7100, C 1\n",
      "8 >> Document 11378, C 0\n",
      "9 >> Document 50948, C 2\n",
      "10 >> Document 30734, C 3\n",
      "\n",
      "Cluster Representation in FAIR SEARCH ENGINE\n",
      "Counter({1: 4, 3: 3, 0: 3})\n",
      "\n",
      "1 >> Document 51128, C 3\n",
      "2 >> Document 48813, C 1\n",
      "3 >> Document 903, C 0\n",
      "4 >> Document 25038, C 3\n",
      "5 >> Document 54941, C 0\n",
      "6 >> Document 17968, C 0\n",
      "7 >> Document 7100, C 3\n",
      "8 >> Document 11378, C 1\n",
      "9 >> Document 50948, C 1\n",
      "10 >> Document 30734, C 1\n",
      "\n",
      "----RANKS OBTAINED------\n",
      "Not Fair:  [30172, 36439, 29179, 48818, 9406, 27867, 52028, 15416, 39375, 20657]\n",
      "Fair:      [51128, 48813, 903, 25038, 54941, 17968, 7100, 11378, 50948, 30734]\n",
      "Spearmans Rank Correlation -0.19 and p_value 0.6.\n",
      "Kendalls Rank Correlation -0.16 and p_value 0.6.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for query in query_list:\n",
    "    print('Query >> ',query)\n",
    "    \n",
    "    doc,clusters_notfair = se.return_top_n_doc_fair(query,SEARCH_SPACE,c_labels=l_dict,show=False, authority=None)\n",
    "    \n",
    "    doc_not_fair = doc.copy()\n",
    "    \n",
    "    sim_dict = se.compute_sim_doc_set(query,doc)\n",
    "    \n",
    "    print_clusters_in_result(doc,clusters_notfair,TOP)\n",
    "    \n",
    "    FAIR_RANK = FAIRNESS_Re_Ranking(doc_not_fair,sim_dict,c_prob,l_dict,lambda_value,Fair_Rank_size,SAMPLE_SIZE)\n",
    "    FAIR_RANK.Re_Ranking_Fairness(print_labels = True,show = False)\n",
    "    \n",
    "    corr, p_value = stats.spearmanr(doc_not_fair[:FAIR_RANK.Rank_size],FAIR_RANK.fair_set)\n",
    "    tau, p_value_k = stats.kendalltau(doc_not_fair[:FAIR_RANK.Rank_size],FAIR_RANK.fair_set)\n",
    "    \n",
    "    print_clusters_in_result(FAIR_RANK.fair_set,FAIR_RANK.clusters_res,FAIR_RANK.Rank_size,title='FAIR SEARCH ENGINE')\n",
    "\n",
    "    print('----RANKS OBTAINED------')\n",
    "    print('Not Fair: ', doc_not_fair[:FAIR_RANK.Rank_size])\n",
    "    print('Fair:     ',FAIR_RANK.fair_set )\n",
    "    print('Spearmans Rank Correlation {} and p_value {}.'.format(np.round(corr,2),np.round(p_value,2)))\n",
    "    print('Kendalls Rank Correlation {} and p_value {}.'.format(np.round(tau,2),np.round(p_value_k,2)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
